[{"content":"记录是为了更好地生活。\n","date":"25 March 2024","permalink":"/diary/","section":"","summary":"记录是为了更好地生活。","title":""},{"content":"","date":"25 March 2024","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"傍晚天空突然下起中雨，于是取消了羽毛球预约。于是在家学习Spring Securoty，花了很多都没有打通，心情就会变得焦躁，觉得自己花了特别多的沉没成本。\n但幸好有付出就有收获，只是不是像短视频那样的即时和强烈的反馈。\n又一次尝到了内酚酞的甜。\n","date":"25 March 2024","permalink":"/diary/2024/2024-03-23-keep-going/","section":"","summary":"傍晚天空突然下起中雨，于是取消了羽毛球预约。于是在家学习Spring Securoty，花了很多都没有打通，心情就会变得焦躁，觉得自己花了特别多的沉没成本。","title":"Keep Going"},{"content":"","date":"25 March 2024","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"25 March 2024","permalink":"/tags/%E6%97%A5%E8%AE%B0/","section":"Tags","summary":"","title":"日记"},{"content":"","date":"25 March 2024","permalink":"/categories/%E7%8E%B2%E7%8F%91%E9%9B%95%E5%BF%83/","section":"Categories","summary":"","title":"玲珑雕心"},{"content":"行动是通往知识的唯一道路。\n","date":"23 March 2024","permalink":"/posts/2024/","section":"","summary":"行动是通往知识的唯一道路。","title":""},{"content":"日拱一卒，功不唐捐。\n","date":"23 March 2024","permalink":"/posts/","section":"","summary":"日拱一卒，功不唐捐。","title":""},{"content":"现在经常看技术性的文档和概念，如果是比较常见的，都会首先在搜索框里加上阮一峰这个关键词。\n阮老师的文档在中文互联网算得上独一份。\n","date":"23 March 2024","permalink":"/diary/2024/2024-03-23-read-docs-notes/","section":"","summary":"现在经常看技术性的文档和概念，如果是比较常见的，都会首先在搜索框里加上阮一峰这个关键词。","title":"学习有感"},{"content":"","date":"23 March 2024","permalink":"/tags/angular/","section":"Tags","summary":"","title":"Angular"},{"content":"//TODO 有空学一下GitLens，我发现功能非常强大，并且基本涵盖了Git History和Git Graph的功能。\nJSON Web Token 入门教程\n笔记在代码里： angular-realworld-example-app forked from gothinkster/angular-realworld-example-app\n","date":"23 March 2024","permalink":"/posts/2024/read-angular-real-world-project-code/","section":"","summary":"//TODO 有空学一下GitLens，我发现功能非常强大，并且基本涵盖了Git History和Git Graph的功能。","title":"Read Angular Real World Project Code"},{"content":"","date":"23 March 2024","permalink":"/categories/%E5%89%8D%E7%AB%AF/","section":"Categories","summary":"","title":"前端"},{"content":"","date":"23 March 2024","permalink":"/tags/%E5%AD%A6%E4%B9%A0%E6%BA%90%E7%A0%81/","section":"Tags","summary":"","title":"学习源码"},{"content":"","date":"19 March 2024","permalink":"/tags/oauth/","section":"Tags","summary":"","title":"OAuth"},{"content":"参考；\n阮一峰老师系列课程：\nOAuth 2.0 的一个简单解释 理解OAuth 2.0 OAuth 2.0 的四种方式 现实中的OAuth # 阮一峰老师举了快递员进小区的例子。小区就是一个服务，里面是我的数据。\n我可以通过用户名和密码通过门禁进入小区。但是有时候快递小哥（第三方应用）也需要进入门禁（仅限于通过小区门禁），来收发快递。\n如果我把密码告诉快递员，显然不安全（权限过高），取消权限也很麻烦（需要我改密码）。怎么让快递员在进入小区的便捷性和安全性间取得平衡。\n授权机制的设计 # 门禁系统的密码输入器下面，增加一个按钮，叫做\u0026quot;获取授权\u0026quot;。快递员需要首先按这个按钮，去申请授权。 他按下按钮以后，屋主（也就是我）的手机就会跳出对话框：有人正在要求授权。系统还会显示该快递员的姓名、工号和所属的快递公司。 门禁系统得到我的确认以后，向快递员显示一个进入小区的令牌（access token）。令牌就是类似密码的一串数字，只在短期内（比如七天）有效。 快递员向门禁系统输入令牌，进入小区。 什么是OAuth # 有了前面的案例，就能更好的理解。\nOAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。\nOAuth 的核心就是向第三方应用颁发令牌。\n令牌相对密码有三点差异；\n（1）令牌是短期的，到期会自动失效，用户自己无法修改。密码一般长期有效，用户不修改，就不会发生变化。 （2）令牌可以被数据所有者撤销，会立即失效。以上例而言，屋主可以随时取消快递员的令牌。密码一般不允许被他人撤销。 （3）令牌有权限范围（scope），比如只能进小区的二号门。对于网络服务来说，只读令牌就比读写令牌更安全。密码一般是完整权限。\nRFC 6749 # OAuth 2.0 的标准是 RFC 6749 文件。\nOAuth 引入了一个授权层，用来分离两种不同的角色：客户端和资源所有者。\u0026hellip;\u0026hellip;资源所有者同意以后，资源服务器可以向客户端颁发令牌。客户端通过令牌，去请求数据。\nOAuth 2.0 规定了四种获得令牌的流程。\n授权码（authorization-code） 隐藏式（implicit） 密码式（password）： 客户端凭证（client credentials） 前提 # 不管哪一种授权方式，第三方应用申请令牌之前，都必须先到系统备案，说明自己的身份，然后会拿到两个身份识别码：客户端 ID（client ID）和客户端密钥（client secret）。\n这是为了防止令牌被滥用，没有备案过的第三方应用，是不会拿到令牌的。\n也就是说，得确认你这个人是快递员才有资格请求令牌。其它冒充的通不过身份验证。\n第一种授权方式：授权码 # 授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。（这种的安全性最高），像令牌。密钥都是存储在后端，前端（浏览器）没有这些信息，避免令牌泄露。\n以下都是假设A网站要请求B网站的授权。\n第一步 请求授权码 # A会向B的授权API请求，让B知道是谁在请求，要求返回授权码，返回的重定向地址。\nhttps://b.com/oauth/authorize? response_type=code\u0026amp; client_id=CLIENT_ID\u0026amp; redirect_uri=CALLBACK_URL\u0026amp; scope=read 第二步 返回授权码 # 用户跳转后，B 网站会要求用户登录，然后询问是否同意给予 A 网站授权。用户表示同意，这时 B 网站就会跳回redirect_uri参数指定的网址。跳转时，会传回一个授权码。\nhttps://a.com/callback?code=AUTHORIZATION_CODE 第二步A拿到了B的授权码，也就是我觉得你的请求是合理的，允许你继续申请令牌。(但是为什么不就在这里直接返回令牌呢？因为这是从A前端发送的请求，我们不知道到底是是不是A的请求，因为很容易被伪造，没有能够验证身份特征的东西，就算有，在前端也是不可靠的，所以生成了一次性的验证码。那为什么不直接点击就让A的后端开始请求呢？)\n第三步 请求令牌 # A 网站拿到授权码以后，就可以在后端，向 B 网站请求令牌。\nhttps://b.com/oauth/token? client_id=CLIENT_ID\u0026amp; client_secret=CLIENT_SECRET\u0026amp; grant_type=authorization_code\u0026amp; code=AUTHORIZATION_CODE\u0026amp; redirect_uri=CALLBACK_URL 上面 URL 中，client_id参数和client_secret参数用来让 B 确认 A 的身份（client_secret参数是保密的，因此只能在后端发请求），grant_type参数的值是AUTHORIZATION_CODE，表示采用的授权方式是授权码，code参数是上一步拿到的授权码，redirect_uri参数是令牌颁发后的回调网址。\n第四步 返回令牌 # B 网站收到请求以后，就会颁发令牌。具体做法是向redirect_uri指定的网址，发送一段 JSON 数据。\nA 网站在后端拿到 B 网站颁发的令牌。\n第二种方式：隐藏式 # 密码登陆很重要，是把关令牌请求是否有效安全可信的关键。\nHTTP 的重定向 # ","date":"19 March 2024","permalink":"/posts/2024/oauth/","section":"","summary":"参考；","title":"Oauth 了解和实践"},{"content":"","date":"19 March 2024","permalink":"/categories/%E5%90%8E%E6%AE%B5/","section":"Categories","summary":"","title":"后段"},{"content":"","date":"19 March 2024","permalink":"/tags/gradle/","section":"Tags","summary":"","title":"Gradle"},{"content":"Reference: Gradle Version Catalog 和 Version Catalog(中央依赖声明，即：版本目录)\n以前一直很好奇，Spring Boot Starter是怎么进行包的版本管理的，看完这个就可以获得启发。\n好处 # 统一的模块的依赖版本管理 依赖分组 \u0026hellip; 在Gradle 8.0后的版本，默认已经支持了Gradle Catalog.\nFeature # [versions]用于声明可以被依赖项引用的版本 [libraries] 用于声明依赖的别名 [bundles] 用于声明依赖包（依赖组） [plugins] 用于声明插件 新建gradle/libs.versions.toml文件：\n[versions] springdoc_version = \u0026#34;2.4.0\u0026#34; [libraries] springdoc = { module = \u0026#34;org.springdoc:springdoc-openapi-starter-webmvc-ui\u0026#34;, version.ref = \u0026#34;springdoc_version\u0026#34; } [bundles] springdoc = [\u0026#34;springdoc\u0026#34;] [plugins] 使用 # 然后在build.gradle中像正常引用其它包一样引用。\ndependencies { implementation libs.bundles.springdoc } 就这么简单。\n","date":"19 March 2024","permalink":"/posts/2024/gradle_catalog/","section":"","summary":"Reference: Gradle Version Catalog 和 Version Catalog(中央依赖声明，即：版本目录)","title":"Gradle Catalog"},{"content":"","date":"19 March 2024","permalink":"/tags/java/","section":"Tags","summary":"","title":"Java"},{"content":"","date":"19 March 2024","permalink":"/categories/%E6%8A%98%E8%85%BE/","section":"Categories","summary":"","title":"折腾"},{"content":"Official Dosc: spring-boot\nReference: freeCodeCamp.org - Spring Boot \u0026amp; Spring Data JPA – Complete Course\nSpringboot in action # 主要的特性：\nIOC MVC AOP DAF(Data Access Framework) Spring beans in action # Spring bean object lifecycle is managed by the spring container.\n复习Spring Bean的用法 # Spring注解分类（以IOC为中心） # 广义上Spring注解可以分为两类， 注册和消费Bean。\n注册Bean的注解有@Component, @Repository, @Controller, @Service, @Configration, @Bean等。 把对应的类注册到Spring容器中。\n消费Bean的注解有@Autowired，@Resource等，找到容器中对应的Bean对象使用。\n@Bean # @Component, @Repository, @Controller, @Service, @Configration都只能声明在类上，但是如果需要把已有的类放到IOC容器中，上述注解就无能为力了。\n@Configuration public class AppConfig { @Bean public PaymentService paymentService() { return new PaymentService(); } @Bean public DataSource dataSource() { return null; } } @Bean最好与@Configration配合使用。\nBean naming # @Component, @Repository, @Controller, @Service, @Configration等会以类的名称（首字母小写）来命名Bean。\n@Bean会以提供Bean的方法的方法名来命名。\n所有的注册Bean的注解也可以提供名称，来标识Bean。\nDependency Injection # Constructor Injection Field Injection Configuration Methods Injection Setter Methods Injection Field Injection # 属性注入最常见，也就是\n@RestController public class PaymentController { @Autowired private PaymentService paymentService; @GetMapping(\u0026#34;payment\u0026#34;) public String getMethodName(@RequestParam String param) { return this.paymentService.toString(); } } 缺点是无法注入不可变的对象（final修饰的只能在初始化时赋值）。\nConstructor Injection # 注意Spring官方推荐构造方法注入。\n@RestController public class PaymentController { private PaymentService paymentService; @Autowired public PaymentController(PaymentService paymentService) { this.paymentService = paymentService; } @Autowired public PaymentController(PaymentService paymentService, String name) { this.paymentService = paymentService; } @GetMapping(\u0026#34;payment\u0026#34;) public String getMethodName(@RequestParam String param) { return this.paymentService.toString(); } } Configuration Methods Injection # @Service public class PaymentService { @Autowired public void confidClass(PaymentRepository paymentRepository) { System.out.println(paymentRepository.toString()); } } Setter Methods Injection # Java中的getter和setter其实就是常规方法，但符合一定的命名约定，起到控制更新和访问的作用。\n@Qualifier # Qualifier 的意思是合格者，通过这个标示，表明了哪个实现类才是我们所需要的。@Autowired因为是按照类型选择Bean，所以如果有多个相同类型的Bean，就会报错。这个时候就需要@Qualifier的辅助。\n@Primary # 另一个类似的注解是@Primary，如其名，也是和@Bean一起使用。有两个及以上相同类型的Bean注入时，在其中一个上声明@Primary，使用时会优先装配这一个。\nBean Scope # singleton prototype request session application websocket scope用来声明容器中的对象所应该处的限定场景或者说该对象的存活时间，即容器在对象进入其相应的scope之前生成并装配这些对象，在该对象不再处于这些scope的限定之后，容器通常会销毁这些对象.\n@Configuration public class AppConfig { @Bean @Scope(\u0026#34;prototype\u0026#34;) public PaymentService paymentService() { return new PaymentService(); } @Bean @SessionScope public DataSource dataSource() { return null; } } singleton # 单例。在Spring的IoC容器中只存在一个实例，所有对该对象的引用将共享这个实例。\nprototype # 多例。每个请求方可以得到自己对应的一个对象实例。\napplication # 对象实例在应用程序的整个生命周期中存在。\nrequest，session，websocket # 这几个Scope都是Web MVC相关的，对应周期是一个请求的周期，一个会话的周期和一个websocket的周期。\n@Profile # 有点类似Angular中的Environment。在项目运行中，包括多种环境,QA,UAT,PROD等等。 @Profile 注解的作用是指定类或方法在特定的 Profile 环境生效。\n@Configuration @Profile(\u0026#34;prod\u0026#34;) public class JndiDataConfig { @Bean() public DataSource dataSource() throws Exception { Context ctx = new InitialContext(); return (DataSource) ctx.lookup(\u0026#34;java:comp/env/jdbc/datasource\u0026#34;); } } 然后在配置文件中设置需要使用哪一个环境。\nspring: profiles: active: dev 或者\napplicationContext.getEnvironment().setActiveProfiles(\u0026#34;prod\u0026#34;); @Value # @Value注解将配置文件中key对应的值赋值给它标注的属性。\nBest Practice # Split Configuration # @Import主要用于导入类对象与另一个类对象的依赖.\n@Configuration public class ServiceConfig { @Bean public PaymentService paymentService(){ return new ...; } } @Configuration public class RepositoryConfig { @Bean public Accountrepository accountrepository(){ return new ...; } } @Configuration @Import({ServiceConfig.class, RepositoryConfig.class}) public class AppConfig { @Bean public DataSource dataSource(){ return new ...; } } @Import # @Import注解是用来导入配置类或者一些需要前置加载的类.\nWhat is Spring Boot? # 我的理解就是Spring框架的框架，提供一些开箱即用的配置。\nSpring Initialnizer 中的 snapshot 版本 # snapshot是工程版本上的概念，表示快照版本，也就是相对稳定版本，但是会再进行改进，最好不要用于生产环境，在生产环境，应当选择release（发布版本）。\nIDE # Both IDEA and VS Code is ok.\nText Banner Generator # Spring的字符标语是怎么生成的？搜索Text Banner Generator，比如 ascii-banner.\nSpring Boot中可以自定义Banner。在/src/main/resources目录下新建一个banner.txt文件，放入上述网站生成的Banner字符即可。Spring Boot 框架在启动时会查找 banner 信息。\n分析入口程序 # @SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 鼠标放在run上，\nConfigurableApplicationContext org.springframework.boot.SpringApplication.run(Class\u0026lt;?\u0026gt; primarySource, String... args) Static helper that can be used to run a SpringApplication from the specified source using default settings. Parameters: primarySource the primary source to load args the application arguments (usually passed from a Java main method) Returns: the running ApplicationContext 可以看到SpringApplication.run(DemoApplication.class, args);实际上返回了ConfigurableApplicationContext，也就是SpringBoot的运行上下文。\n所以可以通过接口拿到Bean。\n@SpringBootApplication public class DemoApplication { public static void main(String[] args) { ApplicationContext ctx = SpringApplication.run(DemoApplication.class, args); PaymentRepository paymentRepository = ctx.getBean(PaymentRepository.class); System.out.println(paymentRepository.toString()); } } 解析源码 # @Repository, @Controller, @Service实际上都是@Component。\nDI # 这部分是上一部分的总结和实践。不好记录。\nSpring Special Beans # Envirnoment # Spring Boot启动后容器里会存在Environment对象实例，可以在 Environment 中获得系统参数，命令行参数，文件配置等信息。\nEnvironment = Property + Profile\nProperty也就是配置，命令行参数、操作系统环境变量、配置文件等等都归为这一类。\nProfile对应环境。\n我们可以直接在应用中注入Environment对象，获取这些信息。\n@PropertySource # @PropertySource注解用于指定资源文件读取的位置。（默认只能读取application.yaml）\nSpring Profile # 参考Spring beans in action部分的@Profile。\nSpringBoot多环境配置 # 在application.yml同一目录下新建以下三个文件：\napplication-dev.yml：本地开发环境 application-test.yml：测试环境 application-prod.yml：生产环境 那么只需要在配置文件中切换active的环境即可使用对应的配置文件。（application.yml中是通用的配置）\nspring: profiles: active: dev Spring REST # 什么是REST # REST直译是表现层状态转移，很难理解。\n目前看到最好的 解释：\nURL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。\n非常简单高效地实现了接口的规范。\n案例 # 举例说明，要对班级学生进行CRUD，没有REST的话，光Read就有很多种写法：\n{{base_url}}/get_students {{base_url}}/view_students {{base_url}}/list_students 但是遵守REST规范呢？\nGET {{base_url}}/students 删除就是\nDELETE {{base_url}}/students 规范 # 参考： RESTful API 设计指南\n命名必须全部小写 资源（resource）的命名必须是名词，并且必须是复数形式，如果是取一个值，传递id：GET /accounts/1 如果要使用连字符，建议使用‘-’ 嵌套的资源，规范类似：GET /accounts/1/payments/56 POST, GET, PUT, DELETE 方法分别对应CRUD。\n响应码 # 1xx = Informatio（信息） 2xx = Success（成功） 3xx = Redirect（重定向） 4xx = User error（客户端错误） 5xx = Server error（服务器端错误） Spring REST in Action # 基础的用法大概会：\n@Data public class Student { private String name; private String gender; private Integer age; } @RestController @RequestMapping(\u0026#34;/hello\u0026#34;) public class PaymentController { @GetMapping(\u0026#34;payment\u0026#34;) public String getMethodName(@RequestParam(\u0026#39;hello\u0026#39;) String param) { return this.paymentService.toString(); } @PostMapping(\u0026#34;student\u0026#34;) public String postMethodName(@RequestBody String entity) { return entity; } @PostMapping(\u0026#34;student2\u0026#34;) public String studentMethod2(@RequestBody Student student) { return student.toString(); } @GetMapping(\u0026#34;/hello/{user-name}\u0026#34;) public String getMethodName2(@PathVariable(\u0026#34;user-name\u0026#34;) String name) { return \u0026#34;name is\u0026#34; + name; } } @RequestParam @RequestBody @PathVariable @ResponseBody @RequestMapping @ResponseStatus # @ResponseStatus 是 Spring Framework 提供的一个注解，可以设置HTTP请求返回的状态码，使用场景主要用于指定控制器方法抛出异常时的 HTTP 状态码。\nDev Tools \u0026amp; Postman # 教了如何使用DevTools和Postman。基本都会。\n@JsonProperty # @Data public class Student { @JsonProperty(\u0026#34;your_name\u0026#34;) private String name; @JsonProperty(\u0026#34;your_gender\u0026#34;) private String gender; @JsonProperty(\u0026#34;your_age\u0026#34;) private Integer age; } @JsonProperty对实体类属性做映射，把属性名称转换为另一个名称。也就是前端得到的字段key是@JsonProperty中的字段，和后端的实际字段映射。\nRecord # Java16 新特性。\nRecord关键字也是定义类的，主要是为了提供一种更为简洁、紧凑的final类的定义方式。避免了书写setter,getter,toString等等模板代码。\n感觉和Lombok差不多，内置实现。\npublic record StudentRecord( String name, String gender, Integer age) { } @ResponseBody # @ResponseBody的作用是将Java对象转为Json格式的数据。\n@RequestMapping(\u0026#34;/hello\u0026#34;) @ResponseBody public Object hello(String name, String password) { return new DTO(); } 可以看到，return的实际是一个Java对象，需要@ResponseBody转化为Json后才能写入Response发送回前端。\n@RestController # @RestController是一个组合注解，它包含了@Controller和@ResponseBody两个注解的功能（Class Level）。\n@RestController注解在处理请求时，会自动将方法的返回值转换为JSON格式的响应体，并返回给客户端（Class Level）。\nDispatcherServlet # #TODO 还不是很理解，有空需要再看一下 DispatcherServlet详解\nSpring Data JPA # 使用JPA来进行数据持久化。\n引入依赖和连接 # 引入依赖 # dependencies { implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; // 下面这两个就是需要的依赖 implementation \u0026#39;org.springframework.boot:spring-boot-starter-data-jpa\u0026#39; runtimeOnly \u0026#39;com.mysql:mysql-connector-j\u0026#39; } 需要的依赖，一个是JPA，还有一个是给JDBC提供的具体数据库厂商的驱动（实现了JDBC规范）。\n配置和连接JDBC # 数据库的URL可以在类似DBeaver这样的数据库管理软件的连接界面复制，比如：\n下面的配置文件是给JDBC使用的。\nspring: datasource: url: jdbc:mysql://localhost:3306/ username: root password: 20010610 driver-class-name: com.mysql.jdbc.Driver 配置完启动，阅读终端输出信息，发现driver-class-name更名了，所以改为如下格式：\nspring: datasource: url: jdbc:mysql://localhost:3306/helloworld username: root password: 20010610 driver-class-name: com.mysql.cj.jdbc.Driver 配置JPA # spring: jpa: # jpa底层默认使用的ORM框架是hibernate hibernate: # DDL是数据定义语言, 这个字段设置怎么控制数据库里的表 ddl-auto: create # 打印sql show-sql: true properties: hibernate: # 打印格式化的sql \u0026#34;[format_sql]\u0026#34;: true # 数据库方言 dialect: org.hibernate.dialect.MySQLDialect # 这个不是必须的，会自动检测 database: mysql 一些常见的配置可以在 Spring Common Application Properties中查看。\n设置一个 entity 类:\n@Entity public class Teacher { @Id private Integer id; private String firstName; private String lastName; private String email; private Integer age; @Override public String toString() { return \u0026#34;Teacher [id=\u0026#34; + id + \u0026#34;, firstName=\u0026#34; + firstName + \u0026#34;, lastName=\u0026#34; + lastName + \u0026#34;, email=\u0026#34; + email + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } } @Entity # @Entity 说明这个 class 是实体类，并且使用默认的 orm 规则，即 class 名即数据库表中表名，class 字段名即表中的字段名。\n查看@Entity 注解的源码，可以发现它有一个name属性，指定这个实体类的名称。\n@Documented @Target(TYPE) @Retention(RUNTIME) public @interface Entity { /** * (Optional) The entity name. Defaults to the unqualified * name of the entity class. This name is used to refer to the * entity in queries. The name must not be a reserved literal * in the Jakarta Persistence query language. */ String name() default \u0026#34;\u0026#34;; } @Table # @Table 标注的常用选项是 name，用于指明数据库的表名。当实体类与其映射的数据库表名不同名时需要使用 @Table 标注说明。\n@Id # @Id 注解是一个非常重要的注解，它用于映射实体类中的主键字段（所以可以设置与主键相关的一些参数）。\n除了 @Id 注解外，JPA 还提供了许多其他注解，例如 @GeneratedValue、@SequenceGenerator、@TableGenerator 等，用于控制主键生成策略和生成器的配置。\n@Entity @Table(name = \u0026#34;teacher_table\u0026#34;) public class Teacher { @Id @GeneratedValue(strategy = GenerationType.UUID, generator = \u0026#34;\u0026#34;) private UUID id; @Column(name = \u0026#34;first__name\u0026#34;, nullable = false, updatable = false) private String firstName; } @Column # 用来标识实体类中属性与数据表中字段的对应关系。可以点击查看源码，里面有很多属性可以设置（DDL里设置在字段上的控制参数之类的）。其中有一些是前台控制，也就是说是Java 持久层API提供的特性而不是数据库原生的特性。\n@Entity @Table(name = \u0026#34;teacher_table\u0026#34;) public class Teacher { @Id private Integer id; @Column(name = \u0026#34;first__name\u0026#34;, nullable = false, updatable = false) private String firstName; private String lastName; private String email; private Integer age; @Override public String toString() { return \u0026#34;Teacher [id=\u0026#34; + id + \u0026#34;, firstName=\u0026#34; + firstName + \u0026#34;, lastName=\u0026#34; + lastName + \u0026#34;, email=\u0026#34; + email + \u0026#34;, age=\u0026#34; + age + \u0026#34;]\u0026#34;; } } 突然理解了正向工程是啥意思了。暂停课程，系统了解一下正向和逆向。\n正向工程 和 逆向工程 # 正向工程：在Java中创建实体，执行后自动映射成数据库中的表 逆向工程：存在数据库的表，自动生成实体 JPA 支持 正向工程。\nSequences # 序列是一个数据库对象，它允许自动生成值，例如校验号。序列非常适合于生成唯一键值的任务。应用程序可以使用序列来避免用于跟踪数字的列值可能导致的并发性和性能问题。序列相对于在数据库外创建的数字的优势在于，数据库服务器可以跟踪生成的数字。崩溃和重新启动不会导致生成重复的数字。\n这个东西我也是今天才知道。没见用过。\nRepository # Interface Hierarchy # 使用 # @Repository public interface PaymentRepository extends JpaRepository\u0026lt;Teacher, UUID\u0026gt; { } 我们只需要声明这么一个接口，JPA会自动帮我们创建一个实现了这些接口的对象实例，并注入到Spring容器中。\n使用的时候，使用依赖注入，拿到对象实例使用即可(封装，继承，多态)。\n@RestController @RequestMapping(\u0026#34;teacher\u0026#34;) public class TeacherController { private PaymentRepository paymentRepository; public TeacherController(PaymentRepository paymentRepository) { this.paymentRepository = paymentRepository; } @SuppressWarnings(\u0026#34;null\u0026#34;) @PostMapping(\u0026#34;man\u0026#34;) public String postMethodName(@RequestBody Teacher teacher) { // 调用jpa接口提供的方法 this.paymentRepository.save(teacher); return teacher.toString(); } } 插播：HikariCP连接池 # HikariCP是快速、简单、可靠且可用于生产的JDBC连接池。\n依赖 # 在Spring Boot 2.0及以后的版本，不需要在pom.xml或build.gradle中加入HikariCP依赖，因为spring-boot-starter-jdbc和spring-boot-starter-data-jpa会依赖它并且是默认开启的。\n我们可以通过在application.yml中的spring.datasource.hikari中自定义HikariCP连接池的参数。\nspring: application: name: demo datasource: url: jdbc:mysql://localhost:3306/helloworld username: root password: 20010610 driver-class-name: com.mysql.cj.jdbc.Driver # 下面就是hikari的配置。 hikari: # 在连接池中维护的最小空闲连接数 minimum-idle: 10 # 允许一个连接在连接池中闲置的最大时间 idle-timeout: 30000 # 最大连接池数大小 maximum-pool-size: 20 # 连接关闭后的最长生存时间 max-lifetime: 120000 # 客户端从连接池等待连接的最大毫秒数 connection-timeout: 30000 插播：Spring JDBC Template 和 Data Source 和 Spring Data JPA # Spring JDBC Template 和 Spring Data JPA 都是上层建筑，需要配置Data Source来操作数据库，Data Source为数据库的来源（为了显示层级结构，我理解为指向JDBC或者连接池）。\n@OneToOne, @OneToMany, @ManyToOne, @JoinColumn # 这部分没接触过，花了很久我才理解到。\n参考： Difference Between @JoinColumn and mappedBy 和 @JoinColumn 详解\n一对一 # 主表：\n@Entity @Data public class StudentProfile { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer id; @Column private String bio; // mappedBy 表示放弃维护关系，是关系的被维护方 @OneToOne(mappedBy = \u0026#34;studentProfile\u0026#34;) private Student student; } 副表：\n@Entity @Data @Table(name = \u0026#34;student\u0026#34;) public class Student { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer id; @Column(nullable = false, length = 50) @JsonProperty(\u0026#34;firstName\u0026#34;) private String firstName; @Column(nullable = false, length = 50) @JsonProperty(\u0026#34;lastName\u0026#34;) private String lastName; @Column(unique = true, length = 50) @JsonProperty(\u0026#34;email\u0026#34;) private String email; @Column(nullable = true) @JsonProperty(\u0026#34;age\u0026#34;) private Integer age; // 在维护关系的一方，进行级联操作的声明 @OneToOne(cascade = CascadeType.ALL) @JoinColumn(name = \u0026#34;student_profile_id\u0026#34;, referencedColumnName = \u0026#34;id\u0026#34;, nullable = true) private StudentProfile studentProfile; @ManyToOne(cascade = CascadeType.ALL) @JoinColumn(name = \u0026#34;school_id\u0026#34;, referencedColumnName = \u0026#34;id\u0026#34;, nullable = true) private School school; } @JoinColumn # @JoinColumn写在控制关联关系的主控，会在该表中加一个外键。\n@OneToOne # 一对一关系。\n级联操作 # 当有了外键约束的时候，必须先修改或删除副表（有外键的表）中的所有关联数据，才能修改或删除主表（外键引用的表）。\n级联操作可以实现在修改主表的时候，对副表执行相对应的操作（比如删除主主表数据就同时删除对应的所有副表数据）。\n@JsonBackReference 和 @JsonManagedReference # 因为JPA的Entity声明中存在双向引用，所以当打印实体的时候，很容易一直循环调用。这时候就需要@JsonBackReference 和 @JsonManagedReference来避免循环。\n@JsonManagedReference声明在@OneToMany的一方，@JsonBackReference声明在@ManyToOne的一方。\nDTO # DTO stands for data transfer object.\n@Entity中声明的实体类对应的是数据库中的表结构，但是想象一下：\n数据库表结构中字段太多，全部返回给前端效率低下 数据库中有敏感信息（比如地址等），不希望返回给前端 这就是DTO的使用场景。可以设置从前端接受到的数据的DTO和要返回给前端的属性的DTO。\nService Layer # Presentation Layer: Controler Logic Layer: Service Data Access Layer: Repository Service层可以负责实现业务逻辑，是数据获取层和表现层的中间层，进行复杂的运算，读取数据，验证，转换（transformation）。\n分层。测试的时候还可以专注测试服务层的逻辑方法。可复用，健壮性，好处多多。\n文件夹结构 # 除了按照Controller,Service,Repository等层来分类，还可以按照Entity来分类(每个Entity里对应这个Entity的表现层，服务层，持久化层等等)。\nSpring Data Validation # 好处：\nData Integrity Preventing Attacks Error Prevention User Experience (UX) Performance Business Logic Compliance 引入依赖 # dependencies { implementation \u0026#39;org.springframework.boot:spring-boot-starter-validation\u0026#39; } 使用 # 参考： Spring Validation参数效验各种使用姿势\n@Valid 和 @NotEmpty（以这个注解为例） # 只是以@NotEmpty这个注解为例，实际上有非常多的校验注解。\n使用对象接收参数，在需要校验对象的参数加上 @NotBlank注解，然后在需要校验的对象前面的@RequestBody注解的位置再加上@Validated或者@Valid注解。\nExceptionHandler # Spring 提供统一处理方法抛出的异常的注解。当异常发生时，Spring会选择最接近抛出异常的处理方法。\n参考： Spring的@ExceptionHandler注解使用方法\n@ExceptionHandler(MethodArgumentNotValidException.class) public ResponseEntity\u0026lt;?\u0026gt; handleMethodArgumentNotValidException( MethodArgumentNotValidException methodArgumentNotValidException) { var errors = new HashMap\u0026lt;String, String\u0026gt;(); methodArgumentNotValidException.getBindingResult().getAllErrors().forEach(error -\u0026gt; { var fieldName = ((FieldError) error).getField(); var erroeMsg = error.getDefaultMessage(); errors.put(fieldName, erroeMsg); }); return new ResponseEntity\u0026lt;\u0026gt;(errors, HttpStatus.BAD_REQUEST); } Testing Overview # 好处 # Quality Assurance：测试确保函数如期望一样工作，及早找到bug，在到达生产环境前 Regression Testing：确保代码更改后存在的函数还是继续保持正确 Documentation：提供函数该如何使用的样例 Code Maintainability：好的代码实践的一环 Refactoring Confidence：使你自信地重构代码，哪里出错了会马上知道 Collaboration：确保不会影响其他人的数据和代码 Continuous Integration/Continuous Deployment (CI/CD): 在CI/CD时自动执行测试 Reduced Debugging Time：面向测试编程 Scalability：代码越写越多，越来越复杂，测试会让你更加自信不会更改代码触发其它bug Security：排除潜在的安全漏洞 分类 # 单元测试 集成测试 端到端测试 Spring Test In Action # dependencies { testImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39; } spring-boot-starter-test依赖了其他的很多库，提供了非常强大的测试能力。\n@SpringBootTest # SpringBoot程序提供的可以说就是一个ApplicationContext，如果要在测试程序中使用SpringBoot的特性，就需要使用@SpringBootTest注解，它会创建一个与在生产环境中启动的应用程序上下文非常相似的应用程序上下文。\n使用 # 主要的注解和使用方法都可以阅读代码习得。\n@SpringBootTest public class StudentServiceTest { @Autowired private StudentService studentService; @BeforeAll static void beforeAll() { System.out.println(\u0026#34;beforeAll\u0026#34;); } @AfterAll static void afterAll() { System.out.println(\u0026#34;afterAll\u0026#34;); } @BeforeEach void setUp() { System.out.println(\u0026#34;Inside the before each method\u0026#34;); } @AfterEach void tearDown() { System.out.println(\u0026#34;Inside the after each method\u0026#34;); } @Test void testAddStudent() { StudentDto studentDto = new StudentDto(\u0026#34;Helo\u0026#34;, \u0026#34;world\u0026#34;, \u0026#34;213@qq.com\u0026#34;, 1); Student student = this.studentService.toStudent(studentDto); Assertions.assertEquals(studentDto.firstName(), student.getFirstName()); Assertions.assertNotNull(student.getEmail()); } @Test void shouldMapStudentToDtoWhenNull() { Student student = this.studentService.toStudent(null); Assertions.assertEquals(\u0026#34;\u0026#34;, student.getFirstName()); } @Test void shouldMapStudentToDtoWhenNullCustom() { Assertions.assertThrows(NullPointerException.class, () -\u0026gt; this.studentService.toStudent(null)); } } Mockito 模拟测试 # 有时候不想在实际的数据库测试，或者框架还没完全搭好，就需要自己模拟数据。\n具体参考： Java测试框架系列：Mockito使用手册.\n暂时跳过笔记。\nSpringDoc(Spring Fox的下一代) # Spring Fox 已经很久没更新了，Spring Boot3就推荐使用SpringDoc作为文档和接口管理工具。\n引入 # dependencies { implementation group: \u0026#39;org.springdoc\u0026#39;, name: \u0026#39;springdoc-openapi-starter-webmvc-ui\u0026#39;, version: \u0026#39;2.4.0\u0026#39; } 配置 # # 不再使用SpringFox，而是SpringDoc springdoc: api-docs: # http://localhost:8080/api-docs path: /api-docs enabled: true swagger-ui: # 可以通过 http://localhost:8080/swagger-ui/index.html 和 http://localhost:8080/swagger-ui-custom.html 两个地址访问 path: /swagger-ui-custom.html enabled: true 使用 # @RestController @Tag(name = \u0026#34;StudentController\u0026#34;, description = \u0026#34;学生管理\u0026#34;) @RequestMapping(\u0026#34;/v1\u0026#34;) public class StudentController { @SuppressWarnings(\u0026#34;unused\u0026#34;) private StudentService studentService; StudentController(StudentService studentService) { this.studentService = studentService; } @GetMapping(\u0026#34;/student\u0026#34;) @Operation(summary = \u0026#34;获取学生列表\u0026#34;) public List\u0026lt;Student\u0026gt; getAllStudents() { return this.studentService.getAllStudent(); } @PostMapping(\u0026#34;/student\u0026#34;) public String addStudent(@RequestBody Student student) { this.studentService.addStudent(student); return \u0026#34;done\u0026#34;; } } 对应的注解需要使用时再查询即可。\nEnd # 视频从7:34开始就是另外一个案例，看了一下，视频可以关闭了。\n","date":"12 March 2024","permalink":"/posts/2024/springboot/","section":"","summary":"Official Dosc: spring-boot","title":"Jpa insight"},{"content":"","date":"12 March 2024","permalink":"/tags/spring/","section":"Tags","summary":"","title":"Spring"},{"content":"","date":"12 March 2024","permalink":"/tags/spring-boot/","section":"Tags","summary":"","title":"Spring Boot"},{"content":"","date":"12 March 2024","permalink":"/categories/%E5%90%8E%E7%AB%AF/","section":"Categories","summary":"","title":"后端"},{"content":"我知道我不会再来到这里。我的生命史又往前进了一步，距离死亡更近了。\n","date":"17 December 2023","permalink":"/posts/2023/","section":"","summary":"我知道我不会再来到这里。我的生命史又往前进了一步，距离死亡更近了。","title":""},{"content":"参考： 人眼只能分辨24帧？我们来聊聊高刷新率的意义\n首先，建立认知，没有人眼帧率多少的说法，可以认为人眼输入是连续的，输出也是连续的。\n视觉暂留 # 💡 当物体在快速运动时, 人眼所看到的影像消失后，人眼仍能继续保留其影像1/24秒左右的图像，这种现象被称为视觉暂留现象。是人眼具有的一种性质。 人眼观看物体时，成像于视网膜上，并由视神经输入人脑，感觉到物体的像。但当物体移去时，视神经对物体的印象不会立即消失，而要延续1/24秒左右的时间，人眼的这种性质被称为“眼睛的视觉暂留”。\n那么屏幕的高刷新率又有什么用呢？\n事实上，就像我们拍照一样，由于光学成像原理，快门需要经过一段时间的曝光来记录画面，而当被拍摄物体运动时相机就会记录下这段时间物体的运动轨迹。\n当晃动饮料瓶时我拍出了一张曝光时长0.02秒的照片，画面记录下的就是在这0.02秒内瓶子的运动轨迹。这种模糊效果称为动态模糊。\n摄像机也同理，在24帧标准下，理论上电影中的每一帧最大都可以完整记录1÷24≈0.042秒的画面变化（但由于在真实拍摄中移动胶片也需要一定的时间所以实际单帧曝光时间不会这么久，本文以理论最大的0.042秒叙述）。\n可是游戏中显卡渲染画面的原理并不是这样，显卡只会根据当前的场景渲染出每一个瞬间的定格画面，而每个画面前后都没有过渡，因此单帧是没有动态模糊效果的。\n💡 也就是说，电影每秒24帧、每帧曝光0.042秒，加起来正好记录了一秒内画面中的所有变化，时间流逝中产生的动态模糊使画面过渡更平滑；而游戏中的帧数，则是记录了显卡在一秒内渲染出的每一个不连贯的瞬间画面，它与电影最关键的差距就是缺少了时间维度。 关于视觉暂留，实际是指人眼看到的画面消失后在大脑中仍保留了一段时间，因此我们在观察运动物体时视觉上会产生残影的效果。可以说每一瞬间我们看到的都是一次0.1秒曝光的画面，当帧数是24时，暂留时间内画面共显示了24×0.1=2.4帧的内容。\n所以高帧率就是利用人眼的视觉暂留效果，将一个离散的过程变得更连续。\n游戏中的动态模糊 # 这个功能是根据前后帧画面差值来绘制出模糊效果，而非真实记录了画面在每一帧之间的运动状态，与其说是动态，倒不如说是拖影。而且因为现在的游戏电脑运行游戏帧率本来也不低，不像电影那样只有24帧，单帧曝光时间较长。因此这个功能对游戏画面动态的提升并不明显，在实际游戏体验中反而产生一种奇怪的粘滞感。一些晕动症玩家也会产生不适感（俗称晕3D）如果你的硬件太差帧数很低只有二三十帧，那么开启动态模糊后够带来的观感提升倒是会更明显一些，这样才算是能弥补那些负面影响。此外，一些游戏中开启动态模糊也可能会模糊掉一些本不该模糊的内容，或是没有模糊掉一些本该被模糊的内容，这也妨碍到玩家观察游戏画面中的部分环境信息。\n这些问题都受限于当前的算法水平，或许未来游戏动态模糊的实现技术得到改进，我们就可以得到更拟真的动态模糊效果了。\n在现阶段，提升显示帧率仍是直观提升画面顺滑度的解决方案。屏幕刷新率提高的目的是使用户视觉暂留周期能同时存在更多帧数让动画流程更接近现实世界中的物理移动，让动画过渡更加平滑，而并不是为了让用户一帧不落地数出144帧。这样理解，或许你就不会再纠结于人眼识别帧数的问题了。\n","date":"17 December 2023","permalink":"/posts/2023/common/eye/","section":"","summary":"参考： 人眼只能分辨24帧？我们来聊聊高刷新率的意义","title":"动态模糊和高刷新率"},{"content":"","date":"17 December 2023","permalink":"/categories/%E5%B8%B8%E8%AF%86/","section":"Categories","summary":"","title":"常识"},{"content":"","date":"17 December 2023","permalink":"/tags/%E6%91%84%E5%BD%B1/","section":"Tags","summary":"","title":"摄影"},{"content":"","date":"17 December 2023","permalink":"/tags/%E8%A7%86%E8%A7%89/","section":"Tags","summary":"","title":"视觉"},{"content":"","date":"17 December 2023","permalink":"/tags/%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7/","section":"Tags","summary":"","title":"编程技巧"},{"content":"代数数据类型ADT # type Props = { name: string } \u0026amp; ( { gender: \u0026#39;male\u0026#39;; salary: number } | { gender: \u0026#39;female\u0026#39;, weight: number } ) 这样可以动态地根据gender来决定下一个需要的属性是salary还是weight。\ntype ApiResponse\u0026lt;T\u0026gt; = | {status: \u0026#39;success\u0026#39;; data: T; timestamp: Date} | {status: \u0026#39;error\u0026#39;; message: string; timestamp: Date} let response1: ApiResponse\u0026lt;number\u0026gt; = { status: \u0026#39;success\u0026#39;, data: 100, timestamp: new Date() }; let response2: ApiResponse\u0026lt;number\u0026gt; = { status: \u0026#39;error\u0026#39;, message: \u0026#39;error la\u0026#39;, timestamp: new Date() }; ","date":"17 December 2023","permalink":"/posts/2023/frontend/programming-tips/","section":"","summary":"代数数据类型ADT # type Props = { name: string } \u0026amp; ( { gender: \u0026#39;male\u0026#39;; salary: number } | { gender: \u0026#39;female\u0026#39;, weight: number } ) 这样可以动态地根据gender来决定下一个需要的属性是salary还是weight。","title":"编程技巧"},{"content":"","date":"17 December 2023","permalink":"/tags/deep-learning/","section":"Tags","summary":"","title":"Deep Learning"},{"content":"","date":"17 December 2023","permalink":"/categories/ml/dl/","section":"Categories","summary":"","title":"ML/DL"},{"content":"mAP，即_Mean Average Precision，是目标检测领域最常用的评估指标。_\n💡 不同于常用的准确率，精度，召回率（recall），F1等评估指标。目标检测领域需要通过交并比 **IoU（Intersection of Union）来评估。** 参考文章：\n目标检测模型的评估指标mAP详解(附代码）\n综述 # 目标检测问题可以用几个关键词来概括：\n定位 分类 多对象 经典的图：\nGround Truth # 对于任何算法，评估指标需要知道ground truth（真实标签）数据。 我们只知道训练、验证和测试数据集的ground truth。\n对于目标检测问题，ground truth包括图像中物体的类别以及该图像中每个物体的真实边界框(也就是人工标注的对象框)。\nIoU（Intersection over Union） # IoU是预测框与ground truth的交集和并集的比值。\n对于每个类，预测框和ground truth重叠的区域是交集，而横跨的总区域就是并集。\nIoU的计算公式：\n计算precision和recall # 机器学习分类模型评估中常见的性能度量指标 # Accuracy # Precision and Recall # Accuracy虽然常用，但是无法满足所有分类任务需求。\n比如两个类别的数量非常悬殊（maybe 999999999999:1），我们要识别的是小的那个类别。为了提高准确率，最简单的做法是什么？把所有都预测为前者。但这个预测模型一点用都没有。为了突破accuracy的局限，我们需要计算precision和recall。\n对于一个二分类任务，二分类器的预测结果可分为以下4类：\n💡 **Precision从预测结果角度出发**，描述了二分类器预测出来的正例结果中有多少是真实正例，即该二分类器预测的正例有多少是准确的； Recall从真实结果角度出发，描述了测试集中的真实正例有多少被二分类器挑选了出来，即真实的正例有多少被该二分类器召回。\nPrecision和Recall通常是一对矛盾的性能度量指标。\n目标检测问题中的 Precision and Recall # 为了获得True Positives and False Positives，我们需要使用IoU。\n💡 最常用的阈值是0.5，即如果IoU\u003e 0.5，则认为它是True Positive，否则认为是False Positive。 为了计算Recall，我们需要Negatives的数量。由于图片中我们没有预测到物体的每个部分都被视为Negative，因此计算True Negatives比较难办。\n但是我们可以只计算False Negatives，即我们模型所漏检的物体。\n另外一个需要考虑的因素是模型所给出的各个检测结果的置信度。通过改变置信度阈值，我们可以改变一个预测框是Positive还是 Negative，即改变预测值的正负性(不是box的真实正负性，是预测正负性)。\n然后就可以根据上面给的公式计算目标检测结果的Precision and Recall了。\nmAP # 💡 目标检测中衡量识别精度的指标是mAP（mean average precision）。 多个类别物体检测中，每一个类别都可以根据recall和precision绘制一条曲线，AP就是该曲线下的面积，mAP是多个类别AP的平均值。\n参考：\n目标检测中的mAP是什么含义？ - 隔壁大王的回答 - 知乎 https://www.zhihu.com/question/53405779/answer/139037721\n目标检测模型的评估指标mAP详解(附代码） - 小小将的文章 - 知乎 https://zhuanlan.zhihu.com/p/37910324\n如前面所述，至少有两个变量会影响Precision和Recall，即IoU和置信度阈值。\nIoU是一个简单的几何度量，可以很容易标准化，比如在PASCAL VOC竞赛中采用的IoU阈值为0.5，而COCO竞赛中在计算mAP较复杂，其计算了一系列IoU阈值（0.05至0.95）下的mAP。\n但是置信度却在不同模型会差异较大，可能在我的模型中置信度采用0.5却等价于在其它模型中采用0.8置信度，这会导致precision-recall曲线变化。\n为此，PASCAL VOC组织者想到了一种方法来解决这个问题，即要采用一种可以用于任何模型的评估指标。\n可以看到，为了得到precision-recall曲线，首先要对模型预测结果进行排序（ranked output，按照各个预测值置信度降序排列）。那么给定一个rank，Recall和Precision仅在高于该rank值的预测结果中计算，改变rank值会改变recall值。这里共选择11个不同的recall（[0, 0.1, \u0026hellip;, 0.9, 1.0]），可以认为是选择了11个rank，由于按照置信度排序，所以实际上等于选择了11个不同的置信度阈值。那么，AP就定义为在这11个recall下precision的平均值，其可以表征整个precision-recall曲线（曲线下面积）。\n总而言之就是，有两个变量会影响Precision和Recall，即IoU和置信度阈值，置信度阈值不同，对评估结果影响很大。取平均来抵消影响。\n","date":"17 December 2023","permalink":"/posts/2023/ml/map/","section":"","summary":"mAP，即_Mean Average Precision，是目标检测领域最常用的评估指标。_","title":"目标检测模型的评估指标mAP详解"},{"content":"","date":"17 December 2023","permalink":"/tags/ros/","section":"Tags","summary":"","title":"ROS"},{"content":"","date":"17 December 2023","permalink":"/tags/ubuntu/","section":"Tags","summary":"","title":"Ubuntu"},{"content":"官网 # The Robot Operating System (ROS) is a set of software libraries and tools that help you build robot applications. From drivers to state-of-the-art algorithms, and with powerful developer tools, ROS has what you need for your next robotics project. And it\u0026rsquo;s all open source.\nWiki # Robot Operating System - Wikipedia\nRobot Operating System (ROS or ros) is an open-source robotics middleware suite. Although ROS is not an operating system (OS) but a set of software frameworks for robot software development, it provides services designed for a heterogeneous computer cluster such as hardware abstraction, low-level device control, implementation of commonly used functionality, message-passing between processes, and package management. Running sets of ROS-based processes are represented in a graph architecture where processing takes place in nodes that may receive, post, and multiplex sensor data, control, state, planning, actuator, and other messages. Despite the importance of reactivity and low latency in robot control, ROS is not a real-time operating system (RTOS). However, it is possible to integrate ROS with real-time code.The lack of support for real-time systems has been addressed in the creation of ROS 2, a major revision of the ROS API which will take advantage of modern libraries and technologies for core ROS functions and add support for real-time code and embedded system hardware.\n博客 # Ubuntu是一个以桌面应用为主的Linux操作系统，而raspbian是针对 Raspberry Pi 专门优化、基于 Debian 的 Raspbian OS。\nROS说是叫机器人操作系统，其实并不是像Ubuntu那样完整的系统，可以理解成ROS一个中间件或者一个库，它需要跑在Ubuntu系统上，或者raspbian系统上。\n树莓派是硬件，是操作系统 Ubuntu或者raspbian的载体，安装了ROS的Ubuntu系统才能使用ROS中的工具，框架等。\n自定义消息 # catkin_create_pkg custom_message roscpp std_msgs geometry_msgs message_generation 与之前不同的是，需要在packages.xml中添加如下前两行信息（注意，不是第三行，那种写法已经消失）。\n\u0026lt;build_depend\u0026gt;message_generation\u0026lt;/build_depend\u0026gt; \u0026lt;exec_depend\u0026gt;message_generation\u0026lt;/exec_depend\u0026gt; \u0026lt;!-- \u0026lt;exec_depend\u0026gt;message_runtime\u0026lt;/exec_depend\u0026gt; --\u0026gt; CMakeLists.txt如下：\ncmake_minimum_required(VERSION 3.0.2) project(custom_message) find_package(catkin REQUIRED COMPONENTS geometry_msgs message_generation roscpp std_msgs ) # 新增 add_message_files( FILES Person.msg ) # 新增 generate_messages( DEPENDENCIES std_msgs ) # 新增 catkin_package( CATKIN_DEPENDS geometry_msgs message_generation roscpp std_msgs ) include_directories( ${catkin_INCLUDE_DIRS} ) add_executable(talker1 src/talker1.cpp) target_link_libraries(talker1 ${catkin_LIBRARIES}) add_executable(listener1 src/listener1.cpp) target_link_libraries(listener1 ${catkin_LIBRARIES}) talker代码（注意自定义消息头文件的引入方法是：功能包名 + 消息名，使用时都需要指出命名空间为功能包的名称）：\n#include \u0026lt;sstream\u0026gt; #include \u0026#34;ros/ros.h\u0026#34; #include \u0026#34;custom_message/Person.h\u0026#34; int main(int argc, char **argv) { // ROS节点初始化 ros::init(argc, argv, \u0026#34;talker1\u0026#34;); // 创建节点句柄 ros::NodeHandle n(\u0026#34;hello\u0026#34;); // 创建一个Publisher，发布名为chatter的topic，消息类型为custom_messages::Person ros::Publisher chatter_pub = n.advertise\u0026lt;custom_message::Person\u0026gt;(\u0026#34;custom_msg\u0026#34;, 1000); // 设置循环的频率 ros::Rate loop_rate(10); int count = 0; while (ros::ok()) { // 初始化std_msgs::String类型的消息 custom_message::Person msg; msg.name = \u0026#34;Lucas Tan\u0026#34;; msg.sex = custom_message::Person::unknown; // 发布消息 ROS_INFO(\u0026#34;%s\u0026#34;, msg.name.c_str()); chatter_pub.publish(msg); // 循环等待回调函数 ros::spinOnce(); // 按照循环频率延时 loop_rate.sleep(); ++count; } return 0; } listener代码：\n#include \u0026#34;ros/ros.h\u0026#34; #include \u0026#34;custom_message/Person.h\u0026#34; // 接收到订阅的消息后，会进入消息回调函数 void chatterCallback(const custom_message::Person::ConstPtr\u0026amp; msg) { // 将接收到的消息打印出来 ROS_INFO(\u0026#34;I heard: [%s]\u0026#34;, msg-\u0026gt;name.c_str()); } int main(int argc, char **argv) { // 初始化ROS节点 ros::init(argc, argv, \u0026#34;listener1\u0026#34;); // 创建节点句柄 ros::NodeHandle n(\u0026#34;hello\u0026#34;); // 创建一个Subscriber，订阅名为chatter的话题，注册回调函数chatterCallback ros::Subscriber sub = n.subscribe(\u0026#34;custom_msg\u0026#34;, 1000, chatterCallback); // 循环等待回调函数 ros::spin(); return 0; } 最终效果：\nstd_msgs # 通过rosmsg命令可以方便地查看有哪些msg功能包以及msg的结构。\nroot@f90027cc500f:~# rosmsg -h rosmsg is a command-line tool for displaying information about ROS Message types. Commands: rosmsg show\tShow message description rosmsg info\tAlias for rosmsg show rosmsg list\tList all messages rosmsg md5\tDisplay message md5sum rosmsg package\tList messages in a package rosmsg packages\tList packages that contain messages Type rosmsg \u0026lt;command\u0026gt; -h for more detailed usage 比如看Image的结构（不用到处找包的位置进去看，我是🤡）\nros::spin() 和 ros::spinOnce()区别 # 首先明确，这两个都是**ROS消息回调处理函数。**也就是说是用于订阅者的。\n区别 # ros::**spin()**在调用后不会再返回，也就是你的主程序到这儿就不往下执行了，而是进行下一次回调。（ros::spin()函数一般不会出现在循环中，因为程序执行到spin()后就不调用其他语句了，也就是说该循环没有任何意义）。\n而 **ros::spinOnce()**后者在调用后还可以继续执行之后的程序，但往往需要考虑调用消息的时机，调用频率，以及消息池的大小。\n通常和循环以及loop_rate.sleep()一起使用。\n代码对比区别 # talker # #include \u0026#34;ros/ros.h\u0026#34; #include \u0026#34;std_msgs/String.h\u0026#34; // Why we need sstream? Because we need this to split a sentence to words. #include \u0026lt;sstream\u0026gt; int main(int argc, char **argv) { // init, can not have namespace ros::init(argc, argv, \u0026#34;talker\u0026#34;); // start, this is a c11 initialization mode ros::NodeHandle n(\u0026#34;namespace\u0026#34;); // Define publisher\u0026#39;s topic name and msg type. ros::Publisher chatter_pub = n.advertise\u0026lt;std_msgs::String\u0026gt;(\u0026#34;chatter\u0026#34;, 1000); // set loop rate(per sec) ros::Rate loop_rate(10); int count = 0; // ros::ok()在以下几种情况下会返回false, 按下Ctrl-C时。我们被一个同名同姓的节点从网络中踢出。ros::shutdown()被应用程序的另一部分调用。所有的ros::NodeHandles都被销毁了。 while (ros::ok()) { std_msgs::String msg; std::stringstream ss; ss \u0026lt;\u0026lt; \u0026#34;hello world \u0026#34; \u0026lt;\u0026lt; count; msg.data = ss.str(); ROS_INFO(\u0026#34;%s\u0026#34;, msg.data.c_str()); /** * 向 Topic: chatter 发送消息, 发送频率为10Hz（1秒发10次）；消息池最大容量1000。 */ chatter_pub.publish(msg); // 如果运行到下一次loop.sleep()后未达到设置的时间，则会开始休眠，等到后再执行下一句 loop_rate.sleep(); ++count; } return 0; } listener：spin() # #include \u0026#34;ros/ros.h\u0026#34; #include \u0026#34;std_msgs/String.h\u0026#34; // subscriber callback function void chatterCallback(const std_msgs::String::ConstPtr\u0026amp; msg) { ROS_INFO(\u0026#34;I heard: [%s]\u0026#34;, msg-\u0026gt;data.c_str()); } int main(int argc, char **argv) { ros::init(argc, argv, \u0026#34;listener\u0026#34;); ros::NodeHandle n(\u0026#34;namespace\u0026#34;); ros::Subscriber sub = n.subscribe(\u0026#34;chatter\u0026#34;, 1000, chatterCallback); /** * ros::spin() 将会进入循环， 一直调用回调函数chatterCallback(),每次调用1000个数据。 * 当用户输入Ctrl+C或者ROS主进程关闭时退出， */ ros::spin(); return 0; } listener：spinOnce() # #include \u0026#34;ros/ros.h\u0026#34; #include \u0026#34;std_msgs/String.h\u0026#34; // subscriber callback function void chatterCallback(const std_msgs::String::ConstPtr\u0026amp; msg) { ROS_INFO(\u0026#34;I heard: [%s]\u0026#34;, msg-\u0026gt;data.c_str()); } int main(int argc, char **argv) { ros::init(argc, argv, \u0026#34;listener\u0026#34;); ros::NodeHandle n(\u0026#34;namespace\u0026#34;); ros::Subscriber sub = n.subscribe(\u0026#34;chatter\u0026#34;, 1000, chatterCallback); ros::Rate loop_rate(5); while(ros::ok()){ ros::spinOnce(); loop_rate.sleep(); } return 0; } Ros \u0026amp; OpenCV # ros to opencv # 要理解，核心是在opencv。ros只是一个输入的工具。\n#include \u0026lt;ros/ros.h\u0026gt; // Using image_transport for publishing and subscribing to images in ROS allows you to subscribe to compressed image streams. #include \u0026lt;image_transport/image_transport.h\u0026gt; #include \u0026lt;cv_bridge/cv_bridge.h\u0026gt; // some useful constants and functions related to image encodings. #include \u0026lt;sensor_msgs/image_encodings.h\u0026gt; // OpenCV\u0026#39;s image processing and GUI modules. #include \u0026lt;opencv2/imgproc/imgproc.hpp\u0026gt; #include \u0026lt;opencv2/highgui/highgui.hpp\u0026gt; static const std::string OPENCV_WINDOW = \u0026#34;Image window\u0026#34;; class ImageConverter { ros::NodeHandle nh_; // image_transport类：图像传输类，其功能和ROS中的Publisher和Subscriber差不多，但是不同的是这个类在发布和订阅图片消息的同时还附带这摄像头的信息。 // 相比较之下, 在ROS中传送图片信息，使用image_transport类要高效的多。 image_transport::ImageTransport it_; image_transport::Subscriber image_sub_; image_transport::Publisher image_pub_; public: ImageConverter() : it_(nh_) { // Subscrive to input video feed and publish output video feed image_sub_ = it_.subscribe(\u0026#34;/camera/image_raw\u0026#34;, 1, \u0026amp;ImageConverter::imageCb, this); image_pub_ = it_.advertise(\u0026#34;/image_converter/output_video\u0026#34;, 1); // OpenCV HighGUI calls to create/destroy a display window on start-up/shutdown. cv::namedWindow(OPENCV_WINDOW); } ~ImageConverter() { cv::destroyWindow(OPENCV_WINDOW); } void imageCb(const sensor_msgs::ImageConstPtr \u0026amp;msg) { // CvBridge defines a CvImage type containing an OpenCV image, its encoding and a ROS header. // 中文说的话就是： cv_bidge::CvImage类：cv_bridge中提供的数据结构，里面包括OpenCV中的cv::Mat类型的图像信息，图像编码方式，ROS头文件等等。 cv_bridge::CvImagePtr cv_ptr; try { // Note that OpenCV expects color images to use BGR channel order. cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8); } catch (cv_bridge::Exception \u0026amp;e) { ROS_ERROR(\u0026#34;cv_bridge exception: %s\u0026#34;, e.what()); return; } // Draw an example circle on the video stream if (cv_ptr-\u0026gt;image.rows \u0026gt; 60 \u0026amp;\u0026amp; cv_ptr-\u0026gt;image.cols \u0026gt; 60) cv::circle(cv_ptr-\u0026gt;image, cv::Point(50, 50), 10, CV_RGB(255, 0, 0)); // Update GUI Window cv::imshow(OPENCV_WINDOW, cv_ptr-\u0026gt;image); cv::waitKey(3); // Output modified video stream image_pub_.publish(cv_ptr-\u0026gt;toImageMsg()); } }; int main(int argc, char **argv) { ros::init(argc, argv, \u0026#34;image_converter\u0026#34;); ImageConverter ic; ros::spin(); return 0; } 对应的CMakeLists：\ncmake_minimum_required(VERSION 3.0.2) project(opencv_study) find_package(catkin REQUIRED COMPONENTS roscpp rospy sensor_msgs cv_bridge std_msgs image_transport ) catkin_package( # INCLUDE_DIRS include # LIBRARIES opencv_study # CATKIN_DEPENDS roscpp rospy # DEPENDS system_lib ) include_directories( # include ${catkin_INCLUDE_DIRS} ) add_executable(image_converter src/image_converter.cpp) target_link_libraries(image_converter ${catkin_LIBRARIES}) 话题名称重映射 # rosrun opencv_study image_converter /camera/image_raw:=/camera/color/image_raw 这句话将原来订阅的话题/camera/image_raw改名为/camera/color/image_raw。\nros run 后面的参数的意义：\n__ns:= : 更改节点的命名空间 __name:=:更改节点的名称 A:=B:话题重映射，A → B opencv to tos # #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;sstream\u0026gt; using namespace std; // OpenCV includes #include \u0026lt;opencv2/video.hpp\u0026gt; #include \u0026lt;opencv2/opencv.hpp\u0026gt; #include \u0026lt;opencv2/core/core.hpp\u0026gt; #include \u0026lt;opencv2/imgproc/imgproc.hpp\u0026gt; #include \u0026lt;opencv2/calib3d/calib3d.hpp\u0026gt; #include \u0026lt;opencv2/highgui/highgui.hpp\u0026gt; #include \u0026#34;opencv2/imgcodecs/legacy/constants_c.h\u0026#34; using namespace cv; #include \u0026lt;ros/ros.h\u0026gt; #include \u0026lt;cv_bridge/cv_bridge.h\u0026gt; #include \u0026lt;image_transport/image_transport.h\u0026gt; #include \u0026lt;sensor_msgs/image_encodings.h\u0026gt; int main(int argc, char **argv) { ros::init(argc, argv, \u0026#34;image_color\u0026#34;); ros::NodeHandle nh; image_transport::ImageTransport it(nh); image_transport::Publisher pub = it.advertise(\u0026#34;/camera_sim/image_raw\u0026#34;, 1); /**************ROS与Opencv图像转换***********************/ Mat image = imread(\u0026#34;/home/agilex/Desktop/ty/catkin_ws/src/scout_work_1/src/index.jpeg\u0026#34;, CV_LOAD_IMAGE_COLOR); sensor_msgs::ImagePtr msg = cv_bridge::CvImage(std_msgs::Header(), \u0026#34;bgr8\u0026#34;, image).toImageMsg(); ros::Rate loop_rate(5); while (nh.ok()) { pub.publish(msg); ros::spinOnce(); loop_rate.sleep(); } return 0; } ","date":"17 December 2023","permalink":"/posts/2023/common/ros-ubuntu/","section":"","summary":"官网 # The Robot Operating System (ROS) is a set of software libraries and tools that help you build robot applications.","title":"什么是ROS(ROS和Ubuntu的区别)"},{"content":"","date":"17 December 2023","permalink":"/tags/%E6%98%BE%E7%A4%BA%E5%99%A8/","section":"Tags","summary":"","title":"显示器"},{"content":"买显示器时经常会被扑面而来眼花缭乱的各种单位困惑。我发现这种经常会碰到的领域就需要抽空专门把它弄清楚。 类似一个判断语句：\nwhile wait until 该事件出现: 记数器+=1 if 出现频率达到一定要求: 专门抽空研究清楚 break else: 什么都不做 术语汇总 # 720p, 1080p, 2k ,4k PPI 分辨率 每英寸像素数量 HDMI PD HDR HD, FHD, QHD, UHD 位图，矢量图 从像素说起 # 像素分为数码像素与屏幕像素。我们一般说的更多的是数码像素。\n数码像素 # 数码像素是一种虚拟化的数字，大小可以任意，或者说没有实际的物理尺寸大小，所以可以适配显示屏的屏幕像素。\n没有形状，按我的理解就是存储在存储介质中的一些比特串，再上一层可以理解为一个多维数组。\n摄像机CMOS捕获的像素 # 有的摄像机捕获的像素并不是1：1的正方向，比如：1：1.21，1：1.09，1：1.46等等。但是在数码像素层面，始终还是一个数字。\n屏幕像素 # 屏幕像素是指显示屏的像素，包括电视机，电脑显示屏，手机显示屏等等，屏幕像素具有物理尺寸大小，通常是英寸-inch, 这些像素通常来说只有一种比列1：1的正方形，并且像素点之间是紧挨着的。\n分辨率 # 分辨率(resolution，港台称之为解析度)就是屏幕图像的精密度，是指显示器所能显示的像素的多少。由于屏幕上的点、线和面都是由像素组成的，显示器可显示的像素越多，画面就越精细，同样的屏幕区域内能显示的信息也越多，所以分辨率是个非常重要的性能指标之一。\n显示分辨率 # 显示分辨率就是屏幕上显示的像素个数，分辨率160×128的意思是水平像素数为160个，垂直像素数128个。\nPPI（Pixels Per Inch） # 误区 # 首先指出一个误解：通常我们会看到“分辨率1920*1080”，此处分辨率=Resolution,是数码图像的分辨率，与屏幕分辨率ppi和打印机分辨率dpi无关，它表示的是“像素数量”不要理解为面积，跟面积无任何关系。\n什么是PPI # PPI（Pixels Per Inch），从字面意思理解就是每英寸像素，也可以理解为屏幕像素密度，因为像素并没有固定的大小，所以，PPI 越高，[[显示器领域的各种单位#屏幕像素|屏幕像素]]大小越小，也就越清晰。\n$$ PPI = \\frac{d_{p}}{d_{i}} =\\frac{\\sqrt{\\frac{w_{p}^{2}+ h_{p}^{2}}{2}}}{d_{i}} $$ 其中：\n$d_{p}$为屏幕对角线的分辨率 $w_{p}$w为屏幕横向分辨率 $h_{p}$为屏幕横向分辨率 $d_{i}$为屏幕横向分辨率。 所以说屏幕的清晰度取决于屏幕像素密度（PPI）。对于同样大小的两块屏幕，屏幕分辨率越高的屏幕越清晰。\n对于不同大小的屏幕，因为还有观看距离的原因，所以还需要考虑其他因素。\nPPI和DPI # 一个表示数码图像打印分辨率，一个表示打印机分辨率。单位都是英尺。\n打印输出尺寸（inch）= 图像的Resolution/数码图像打印PPI # 当我们定义了打印输出尺寸（inch）和数码图像打印PPI时，打印时的图像的Resolution会自动适配，PPI越高意味着图像的Resolution越高，打印纸张大小不变时，打印更清晰，反之亦然。\n「1080p」和「2k、4k」 # 这是关于分辨率的说法，是不同的分辨率。 目前关于分辨率的说法很混乱，没有统一标准。 所以最好直接看分辨率数值，不要光看这个概念。\n但是好在行业里有约定俗成的叫法，大家都默认短边有1080个像素的屏幕叫1080P，短边有1440个像素的屏幕叫2k。\n正规叫法 HD FHD QHD UHD # 720P——1280*720——HD（高清） 1080P——1920*1080——FHD（全高清） 2K——2560*1440——QHD（四倍高清） 4K——3840*2160——UHD（超高清） 但是这样不利于宣传营销。\n","date":"17 December 2023","permalink":"/posts/2023/common/display-unit/","section":"","summary":"买显示器时经常会被扑面而来眼花缭乱的各种单位困惑。我发现这种经常会碰到的领域就需要抽空专门把它弄清楚。 类似一个判断语句：","title":"显示器领域的各种单位"},{"content":"","date":"16 December 2023","permalink":"/tags/cuda/","section":"Tags","summary":"","title":"CUDA"},{"content":"","date":"16 December 2023","permalink":"/tags/pytorch/","section":"Tags","summary":"","title":"PyTorch"},{"content":"参考：\n显卡，显卡驱动,nvcc, cuda driver,cudatoolkit,cudnn到底是什么？\n一文讲清楚CUDA、CUDA toolkit、CUDNN、NVCC关系_健0000的博客-CSDN博客\nCUDA 和 CUDA toolkit # CUDA并不是软件，而是一个并行计算平台和编程模型，能够使得使用GPU进行通用计算变得简单和优雅。\n我们平时说的安装驱动，然后安装CUDA和cudnn，实际上指的是安装CUDA toolkit和cudnn。\n传统上，安装 NVIDIA Driver 和 CUDA Toolkit 的步骤是分开的，但实际上我们可以直接安装 CUDA Toolkit，系统将自动安装与其版本匹配的 NVIDIA Driver。\n安装网址：\nNVIDIA CUDA Toolkit 11.7 Downloads\nCUDA Toolkit由以下组件组成：\nCUDA 12.1 Release Notes\nCompiler: CUDA-C和CUDA-C++编译器NVCC位于bin/目录中。它建立在NVVM优化器之上，而NVVM优化器本身构建在LLVM编译器基础结构之上。Tools: 提供一些像profiler,debuggers等工具，这些工具可以从bin/目录中获取Libraries: 下面列出的部分科学库和实用程序库可以在lib/目录中使用，它们的接口在include/目录中可获取。CUDA Samples: 演示如何使用各种CUDA和library API的代码示例。CUDA Driver: 运行CUDA应用程序需要系统至少有一个具有CUDA功能的GPU和与CUDA工具包兼容的驱动程序。\ncudnn # NVIDIA CUDA® 深度神经网络库 (cuDNN) 是一个 GPU 加速的深度神经网络基元库，能够以高度优化的方式实现标准例程（如前向和反向卷积、池化层、归一化和激活层）。\n全球的深度学习研究人员和框架开发者都依赖 cuDNN 来实现高性能 GPU 加速。借助 cuDNN，研究人员和开发者可以专注于训练神经网络及开发软件应用，而不必花时间进行低层级的 GPU 性能调整。cuDNN 可加速广泛应用的深度学习框架，包括 Caffe2、 Chainer、 Keras、 MATLAB、 MxNet、 PaddlePaddle、 PyTorch 和 TensorFlow。\n这个toolkit里面不是自带的。所以需要手动安装。\nConda PyTorch 里 CUDA、CUDA toolkit # CUDA Toolkit (Nvidia)： CUDA完整的工具安装包，其中提供了 Nvidia 驱动程序、开发 CUDA 程序相关的开发工具包等可供安装的选项。包括 CUDA 程序的编译器、IDE、调试器等，CUDA 程序所对应的各式库文件以及它们的头文件。\nCUDA Toolkit (PyTorch)： CUDA不完整的工具安装包，其主要包含在使用 CUDA 相关的功能时所依赖的动态链接库。**不会安装驱动程序**。 对于 Pytorch 之类的深度学习框架而言，其在大多数需要使用 GPU 的情况中只需要使用 CUDA 的动态链接库支持程序的运行(**Pytorch 本身与 CUDA 相关的部分是提前编译好的)**，就像常见的可执行程序一样，不需要重新进行编译过程，只需要其所依赖的动态链接库存在即可正常运行。 conda安装的cudatoolkit, cudnn与在主机上安装的cuda, cudnn有何关系 # 首先明确了以下概念：\n本地安装的Nvidia CUDA Toolkit 是 conda 里 toolkit 的超集 运行PyTorch只需要安装驱动和conda里的toolkit即可 查找可用的cuda路径 # 1、环境变量CUDA_HOME 或 CUDA_PATH 2、/usr/local/cuda 3、which nvcc的上级上级目录 （which nvcc 会在环境变量PATH中找） 4、如果上述都不存在，则torch.utils.cpp_extension.CUDA_HOME为None，会使用conda安装的cudatoolkit，其路径为cudart 库文件目录的上级目录（此时可能是通过 conda 安装的 cudatoolkit，一般直接用 conda install cudatoolkit，就是在这里搜索到 cuda 库的）。\n实践 # 根据实践，当同时存在conda里的toolkit和本地的toolkit时，会优先调用conda里的环境。\n参考：\nconda安装的cudatoolkit, cudnn与在主机上安装的cuda, cudnn有何关系？ - 知乎\n其他 # 参考：\nPytorch 使用不同版本的 cuda - yhjoker - 博客园\n","date":"16 December 2023","permalink":"/posts/2023/ml/cuda-more/","section":"","summary":"参考：","title":"英伟达官网 CUDA、CUDA toolkit 和 Conda PyTorch 里 CUDA、CUDA toolkit的关系"},{"content":"单纯型(naive)本地化和时区意识型(time zone-aware) # 当使用datetime.now()得到一个datetime对象的时候，此时该datetime对象没有任何关于时区的信息，即datetime对象的tzinfo属性为None(tzinfo属性被用于存储datetime object关于时区的信息)，该datetime对象就被称为naive datetime object。\n相对的aware datetime object就是指存储了时区信息的datetime object。\nfrom datetime import datetime native = datetime.now() native.tzinfo() # 输出：None import pytz aware = datetime.now(pytz.utc) aware # 输出： datetime.datetime(2023, 5, 13, 12, 24, 26, 500566, tzinfo=\u0026lt;UTC\u0026gt;) GMT # 格林威治皇家天文台为了海上霸权的扩张计划，在十七世纪就开始进行天体观测。为了天文观测，选择了穿过英国伦敦格林威治天文台子午仪中心的一条经线作为零度参考线，这条线，简称格林威治子午线。\n1884年10月在美国华盛顿召开了一个国际子午线会议，该会议将格林威治子午线设定为本初子午线，并将格林威治平时 (GMT, Greenwich Mean Time) 作为世界时间标准（UT, Universal Time）。由此也确定了全球24小时自然时区的划分，所有时区都以和 GMT 之间的偏移量做为参考。\n1972年之前，格林威治时间（GMT）一直是世界时间的标准。1972年之后，GMT 不再是一个时间标准了。\nUTC # UTC（Coodinated Universal Time），协调世界时，又称世界统一时间、世界标准时间、国际协调时间。由于英文（CUT）和法文（TUC）的缩写不同，作为妥协，简称UTC。\nUTC 是现在全球通用的时间标准，全球各地都同意将各自的时间进行同步协调。UTC 时间是经过平均太阳时（以格林威治时间GMT为准）、地轴运动修正后的新时标以及以秒为单位的国际原子时所综合精算而成。\nUTC 比 GMT更精准，以原子时计时，适应现代社会的精确计时。\n本地时间 # 当我们说当前时刻是2019年11月20日早上8:15的时候，我们说的实际上是本地时间。在国内就是北京时间。在这个时刻，如果地球上不同地方的人们同时看一眼手表，他们各自的本地时间是不同的。\n所以，不同的时区，在同一时刻，本地时间是不同的。全球一共分为24个时区，伦敦所在的时区称为标准时区，其他时区按东／西偏移的小时区分，北京所在的时区是东八区。\n时区 # 从格林威治本初子午线起，经度每向东或者向西间隔15°，就划分一个时区，在这个区域内，大家使用同样的标准时间。\n全球共分为24个标准时区，相邻时区的时间相差一个小时。\n时区有好几种表示方式。\n一种是以GMT或者UTC加时区偏移表示，例如：GMT+08:00或者UTC+08:00表示东八区。\nGMT和UTC可以认为基本是等价的，只是UTC使用更精确的原子钟计时，每隔几年会有一个闰秒，我们在开发程序的时候可以忽略两者的误差，因为计算机的时钟在联网的时候会自动与时间服务器同步时间。\n夏令时 # DST（Daylight Saving Time），夏令时又称夏季时间，或者夏时制。 它是为节约能源而人为规定地方时间的制度。一般在天亮早的夏季人为将时间提前一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。 夏令时目前使用越来越少了。\n本地化 # 在计算机中，通常使用Locale表示一个国家或地区的日期、时间、数字、货币等格式。Locale由语言_国家的字母缩写构成，例如，zh_CN表示中文+中国，en_US表示英文+美国。语言使用小写，国家使用大写。\n对于日期来说，不同的Locale，例如，中国和美国的表示方式如下：\nzh_CN：2016-11-30 en_US：11/30/2016 计算机通过Locale来针对当地用户习惯格式化日期、时间、数字、货币等。\nimport locale locale.getdefaultlocale() # 输出：(en_US, \u0026#39;UTF-8\u0026#39;) ","date":"16 December 2023","permalink":"/posts/2023/common/time-zone/","section":"","summary":"单纯型(naive)本地化和时区意识型(time zone-aware) # 当使用datetime.","title":"时间相关概念（GMT, UTC, 时间，时区，naive，time zone-aware，Locale等概念）"},{"content":"期刊分类 # 学术期刊的级别、种类、等级，这篇文章全讲清楚了\nSCI的出版形式有四种：印刷版、光盘版（SCI-CDE）、联机版（SCI-Search）和网络版（SCI-Expanded）。前三种形式发行较早，共计收录3749种学术期刊。随着互联网时代的来临，SCI通过建立网络检索系统，大大扩展了收录范围，形成了网络版的SCI-E数据库。2000年，科技部宣布不再区分SCI与SCI-E，认定两者均属于SCI数据库。2016年，SCI共计收录了8757种期刊，内容涵盖数学、物理、化学、生命科学、医学、生命科学、天文学、地理学、环境科学、材料科学、工程技术等领域。被SCI收录的学术期刊称为SCI期刊，发表于其上的科技论文称为SCI论文。值得注意的是，虽然大部分SCI期刊发表英语论文，但在184种SCI收录的中国期刊中，《化学学报》（Acta Chimica Sinica）、《高等学校化学学报》（Chemical Journal of Chinese Universities）等期刊发表的是中文论文。\n「第一讲」什么是SCI？\nOA # https://en.wikipedia.org/wiki/List_of_open-access_journals\n一篇文章，带你了解什么是开放获取（Open Access）\n开放获取：个人或者机构为出版社提供”文章处理费“，出版社将文献免费向全世界发行。这样，作者不仅保留了著作权，机构不需要支付订阅费，也消除对文献的存取障碍，从而使文献达到最大程度的利用。这是开放获取计划最重要的目标。\n开放获取（Open Access)，严格来说：是作者直接在互联网公开发表自己的科学成果，允许社会公众自由获取、复制、传播或其他任何合法目的的利用，但不得侵犯作者保留的权利。（《布达佩斯开放获取计划》，2002）\nNature 和 Nature 子刊 # 《Nature》《Science》是综合性刊物。下面有很多子刊，子刊领域要窄一些，专门针对某一类别的研究。\n《Nature》出版集团为英国的The Nature Publishing Group，截至到2018年1月14日，以Nature打头的子刊共有51本。\n《自然》杂志为什么有那么多子刊，定位如何？ - 知乎\n","date":"16 December 2023","permalink":"/posts/2023/common/paper-catalog/","section":"","summary":"期刊分类 # 学术期刊的级别、种类、等级，这篇文章全讲清楚了","title":"学术期刊的级别、种类、等级"},{"content":"","date":"16 December 2023","permalink":"/tags/%E7%A7%91%E7%A0%94/","section":"Tags","summary":"","title":"科研"},{"content":"","date":"16 December 2023","permalink":"/tags/%E8%AE%BA%E6%96%87/","section":"Tags","summary":"","title":"论文"},{"content":"","date":"16 December 2023","permalink":"/tags/unicode/","section":"Tags","summary":"","title":"Unicode"},{"content":"","date":"16 December 2023","permalink":"/tags/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","section":"Tags","summary":"","title":"字符编码"},{"content":"参考：\ntop level： 锟斤拷�⊠是怎样炼成的——中文显示“⼊”门指南 lower level: 一听就懂字符集、ASCII、GBK、UTF-8、Unicode、乱码、字符编码、解码问题的讲解 top level 视频的稿子在这里： 锟斤拷�⊠是怎样炼成的——中文显示“⼊”门指南 文字版脚本\n综述 # 计算机只认识0，1二进制编码。电脑显示文字，涉及到三个重要的概念：字符、字符集，和字符编码（编码方式）。\n字符编码，类似索引，根据字符编码显示字符集里对应的字符。类似下图这样：\n需要注意的是，码位和索引不是一个东西！由于[[字符编码（ASCII、GBK、UTF-8、Unicode等）#UTF-8码位变长原理]]这个东西的存在，也就意味着码位和索引不是线性关系！\n乱码原因 # 假设一个场景，就很好理解了。\n我在电脑上保存了一份UTF-8编码的文档，内容如下：\n今天中午吃什么？ 输出如下：\n\\\\\\\\xE4\\\\\\\\xBB\\\\\\\\x8A\\\\\\\\xE5\\\\\\\\xA4\\\\\\\\xA9\\\\\\\\xE4\\\\\\\\xB8\\\\\\\\xAD\\\\\\\\xE5\\\\\\\\x8D\\\\\\\\x88\\\\\\\\xE5\\\\\\\\x90\\\\\\\\x83\\\\\\\\xE4\\\\\\\\xBB\\\\\\\\x80\\\\\\\\xE4\\\\\\\\xB9\\\\\\\\x88\\\\\\\\xEF\\\\\\\\xBC\\\\\\\\x9F 可以看到码位为两个字节。\n如果输入为英文呢？\nhello 输出如下：\n\\\\\\\\x68\\\\\\\\x65\\\\\\\\x6C\\\\\\\\x6C\\\\\\\\x6F 可以看到码位为一个字节（编码格式可以理解为同ASCII）。\n如果我保存的今天中午吃什么？的文档，被理解为ASCII文档，用ASCII编码来打开呢？那么输出肯定就是乱码。\n锟斤拷 # 当 GBK 与 Unicode 激情碰撞之后，噩梦般的上古神器——“锟（kūn）斤拷”就诞生了。 你看啊，当你写出这段文字，点击保存，此时它们就被按照 GBK 编码存储成了这串二进制数字。 然后你把这份文档发给了心爱的人，她用最常见的 UTF-8 编码打开。此时软件就懵逼了，因为它会发现这些东西根本无法正常显示。 此时，Unicode 就会用这个替换符号�，来展示所有无法正确显示的字符。 这时她也懵逼了~心想算了，保存一下发给室友让她帮忙打开吧。在她点击保存的那一瞬间，文档中所有的�字符，就被根据 UTF-8 编码，编码为了 0xEF BF BD。 而收到这份文件的大冤种室友，再次使用 GBK 编码打开了这份文档。此时根据 GBK 编码规则，如果有连续两个问号，那么 EFBF、BDEF、BFBD 这三个码位对应的，正是“锟斤拷”三个字。也就是说，连续两个问号，就对应了一个“锟斤拷”，一串问号，就对应了满屏的“锟斤拷”。 经过这套行云流水的操作，你的爱已经完全找不回来了，坍缩成了无穷无尽的“锟斤拷”。\nUTF-8码位变长原理 # UTF-8码位字节长度不定的原理是：拿码位的前几个比特来作为标志位，比如00,01,10,11。00代表后面两个字节是一个码位，01代表后面3个字节是一个码位，10代表4个字节，11代表5个字节这样。（P.S. 现在想起来原理好简单，以前还想了好久🤣）\n参考[[字符编码（ASCII、GBK、UTF-8、Unicode等）#乱码原因]]这里举的例子。\nEmoji 冷知识 # 由于 Unicode 只规定 emoji 的含义，不管它们具体长啥样，所以决定你看到的 emoji 长啥样的，是字体。\n字体与字符编码的关系 # 字符是一个抽象的概念，在计算机上是以字符编码的形式来存储的，是字符在计算中的代号，但具体要如何在屏幕上显示，并没有做规定，如果要在屏幕上显示对应的文字，仅仅靠字符编码是不够的，还需要字体文件。\n字体规定了字符如何显示，在字体文件中，包含了其支持的字符的显示信息。\n一个字体文件包含一个或者多个字符映射表（Charmap），它的作用就是把一个字符从它的字符编码映射到字形索引，即该字符在字体文件中的位置。字符映射表一般使用 Unicode 作为字形的编码。\n一般一个字符的渲染步骤为：\n加载字体文件； 确定要输出的字体大小； 输入这个字符的编码值； 根据字体文件里面的字符映射表，把编码值转换成字形索引； 根据索引从字体中加载这个字形； 将这个字形渲染成位图，有可能进行加粗、倾斜等变换。 在选择字符映射表时，如果和输入的字符编码不一样，输出的字形要么是错的，要么就根本找不到对应的字形，屏幕上就会显示一个方块字。\n","date":"16 December 2023","permalink":"/posts/2023/common/character-encoding/","section":"","summary":"参考：","title":"字符编码（ASCII、GBK、UTF-8、Unicode等）和字体"},{"content":"Angular新手可能经常会有和我一样的疑问，我明明已经设置了值呀，为什么还是报读到undefined错误呢？有两种常见的原因，异步或者生命周期。今天就先来深入了解一下Angular的生命周期（适用于组件，指令等，因为本质上来说，组件也是指令）。\nAngular Lifecycle # 官方文档： 组件的生命周期。\n钩子方法 用途 时机 ngOnChanges() 当 Angular 设置或重新设置数据绑定的输入属性时响应。该方法接受当前和上一属性值的 SimpleChanges对象 注意： 这发生得比较频繁，所以你在这里执行的任何操作都会显著影响性能。 欲知详情，参阅本文档的使用变更检测钩子。 如果组件绑定过输入属性，那么在 ngOnInit() 之前以及所绑定的一个或多个输入属性的值发生变化时都会调用。 注意： 如果你的组件没有输入属性，或者你使用它时没有提供任何输入属性，那么框架就不会调用ngOnChanges()。 ngOnInit() 在 Angular 第一次显示数据绑定和设置指令/组件的输入属性之后，初始化指令/组件。欲知详情，参阅本文档中的初始化组件或指令。 在第一轮 ngOnChanges() 完成之后调用，只调用一次。而且即使没有调用过 ngOnChanges()，也仍然会调用 ngOnInit()（比如当模板中没有绑定任何输入属性时）。 ngDoCheck() 检测，并在发生 Angular 无法或不愿意自己检测的变化时作出反应。欲知详情和范例，参阅本文档中的自定义变更检测。 紧跟在每次执行变更检测时的 ngOnChanges() 和 首次执行变更检测时的 ngOnInit() 后调用。 ngAfterContentInit() 当 Angular 把外部内容投影进组件视图或指令所在的视图之后调用。 欲知详情和范例，参阅本文档中的响应内容中的变更。 第一次 ngDoCheck() 之后调用，只调用一次。 ngAfterContentChecked() 每当 Angular 检查完被投影到组件或指令中的内容之后调用。 欲知详情和范例，参阅本文档中的响应被投影内容的变更。 ngAfterContentInit() 和每次 ngDoCheck() 之后调用。 ngAfterViewInit() 当 Angular 初始化完组件视图及其子视图或包含该指令的视图之后调用。 欲知详情和范例，参阅本文档中的响应视图变更。 第一次 ngAfterContentChecked() 之后调用，只调用一次。 ngAfterViewChecked() 每当 Angular 做完组件视图和子视图或包含该指令的视图的变更检测之后调用。 ngAfterViewInit() 和每次 ngAfterContentChecked() 之后调用。 ngOnDestroy() 每当 Angular 每次销毁指令/组件之前调用并清扫。在这儿反订阅可观察对象和分离事件处理器，以防内存泄漏。欲知详情，参阅本文档中的在实例销毁时进行清理。 在 Angular 销毁指令或组件之前立即调用。 OnChanges # 注意，只有在当前组件或者指令的@Input/@Output绑定的值变化时会触发这个函数。另外需要注意的是，如果 @Input 是个对象，对象里面的数据改变但是引用没有变化也不会触发这个函数(这就是为什么经常需要使用 lodash的cloneDeep()函数进行深拷贝的原因，本质是改变引用地址)。\nDoCheck # Angular：ngDoCheck执行时机\n父子组件生命周期 # 参考自：\nAngular\u0026ndash;父子组件生命周期钩子(lifecycle hooks)执行过程 Angular Lifecycle Execution flow from parent to child component ","date":"15 December 2023","permalink":"/posts/2023/frontend/angular/angular-insight-lifecycle/","section":"","summary":"Angular新手可能经常会有和我一样的疑问，我明明已经设置了值呀，为什么还是报读到undefined错误呢？有两种常见的原因，异步或者生命周期。今天就先来深入了解一下Angular的生命周期（适用于组件，指令等，因为本质上来说，组件也是指令）。","title":"Angular Insight Lifecycle"},{"content":"","date":"15 December 2023","permalink":"/tags/git/","section":"Tags","summary":"","title":"Git"},{"content":"现在使用Git的频率变高了很多，使用场景也复杂了很多，根据需求总结一些常用的命令。虽然很多图形化工具已经非常还用了，但是命令行还是有类似Write once, execute anywhere.的优势。\nTL;DR; # 拉取分支 # 基础命令 # git clone [repo-link] 拉取指定分支 # git clone -b [branch-name] [repo-link] 拉取并重命名 # 有的分支，我可能会拉取几次到本地，为了避免命名重复，就需要拉取的时候重命名。\ngit clone -b [branch-name] [repo-link] [new-name] 撤销提交 # 分很多情况，比如是否已经提交，远程仓库是否对分支设置有限制策略等。适用命令有：git reset, git revert等。\n已经提交PR并merge到不能直接操作的分支 # 对于Github来说，可以直接在页面上进行Undo操作， Reverting a pull request。所以下面的策略是针对没有这一特性的Bitbucket。 两种办法：\nHow to undo a merge on Bitbucket? Revert a merged pull request on Bitbucket 第一种使用限制很多而且非常危险，更推荐使用第二种，revert。关于这几个支持回溯的命令的区别，参考 atlassian docs: Resetting, checking out \u0026amp; reverting。\n在提交pr的分支（the branch being merged into）或者从被merge的分支（the branch being merged from）新建一个fix分支，然后切到该分支\ngit switch [branch-name] git pull git revert -m 1 [hash of merged commit] git push git push 然后重新提交PR。\n使用这个命令也要很谨慎，最好不要走到这一步，因为根据 git-revert - Revert some existing commits：\nReverting a merge commit declares that you will never want the tree changes brought in by the merge. As a result, later merges will only bring in tree changes introduced by commits that are not ancestors of the previously reverted merge. This may or may not be what you want.\n详情参考： revert-a-faulty-merge.txt\n-m parent-number 配置项 # 配置参考自： git cherry-pick 教程\n如果原始提交是一个合并节点，来自于两个分支的合并，那么 Cherry pick 默认将失败，因为它不知道应该采用哪个分支的代码变动。\n-m配置项告诉 Git，应该采用哪个分支的变动。它的参数parent-number是一个从1开始的整数，代表原始提交的父分支编号。\n一般来说，1号父分支是接受变动的分支（the branch being merged into），2号父分支是作为变动来源的分支（the branch being merged from）。\n查看分支非最新的版本 # 注意，是仅查看，不要修改。\ngit checkout \u0026lt;commit\u0026gt; 回到上一个分支 # 我们经常会切到其他分支，简单操作又切回dev分支。最简单的方法是：\ngit switch - # or git checkout - # 但是推荐使用switch做分支的切换。 merge remote的代码到当前分支 # git pull 其实就是 git fetch 和 git merge FETCH_HEAD 的简写。\ngit pull origin [remote-branch-name] 比如\ngit pull origin master ```· 将远程主机 origin 的 master 分支拉取过来，与本地的当前所在分支合并。 # git 合并本地多个提交为一个提交并推送到远程 假设你需要merge前三个commit为一个单一的commit，运行如下命令： ```sh git rebase -i HEAD~3 然后会进入一个界面，将除了第一个提交之外的pick改成squash，保存，然后修改提交信息即可。细节可以参考： Combining Multiple Commits Into One Prior To Push\ngit 本地分支管理 # git 远程从主分支新建一个feature/fix分支后，本地克隆下来，然后最好不要直接就在这个分支上开始开发，把这个分支想象成自己的主分支，再新建分支进行开发，有时候会省很多事。\n","date":"15 December 2023","permalink":"/posts/2023/git-handbook/","section":"","summary":"现在使用Git的频率变高了很多，使用场景也复杂了很多，根据需求总结一些常用的命令。虽然很多图形化工具已经非常还用了，但是命令行还是有类似Write once, execute anywhere.","title":"Git Handbook"},{"content":"","date":"18 November 2023","permalink":"/categories/ci/cd/","section":"Categories","summary":"","title":"CI/CD"},{"content":"","date":"18 November 2023","permalink":"/series/ci/cd-insight/","section":"Series","summary":"","title":"CI/CD Insight"},{"content":"","date":"18 November 2023","permalink":"/tags/k8s/","section":"Tags","summary":"","title":"K8s"},{"content":"公司使用的OpenShift管理集群。入职以来，这部分一直被我当成一个黑盒，不清楚是怎么自定义的部署规则。记录一下我的学习笔记。\nDocker # 这部分比较熟悉了，跳过。如果熟悉docker-compose的话，想学习k8s会相对更轻松一点。\nk8s # 这是我觉得最好的实践教程了，配合官网教程食用体验极佳： k8s-tutorials\n","date":"18 November 2023","permalink":"/posts/2023/ci-cd/k8s-cd/","section":"","summary":"公司使用的OpenShift管理集群。入职以来，这部分一直被我当成一个黑盒，不清楚是怎么自定义的部署规则。记录一下我的学习笔记。","title":"K8s与CD"},{"content":"","date":"18 November 2023","permalink":"/tags/openshift/","section":"Tags","summary":"","title":"OpenShift"},{"content":"","date":"18 November 2023","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":"","date":"18 November 2023","permalink":"/tags/jenkins/","section":"Tags","summary":"","title":"Jenkins"},{"content":"入职之后，一直对公司的CI/CD流程实现细节一知半解，最近正好需要打包部署一个应用，借此机会一口气把所有黑盒给打开。\nCI # ``\nJenkinsfile # Jenkinsfile语法规则是基于Groovy语言的DSL。\n官方教程： Jenkins 入门指南\n扩展共享库 # 项目Jenkinsfile中的第一行基本都是:\n@Library(\u0026#39;my-shared-library\u0026#39;) _ 一直很好奇这句话的意思，没想到背后的东西挺多，一直回顾到Groovy语言。但其实只要看官方教程地址： 扩展共享库就能很快地了解这是什么。（我之前一直不知道怎么搜索这个语法的原理）\n在 Jenkinsfile 中使用 @Library('my-shared-library') _ 这种语法是 Jenkins 的一种特殊功能，允许你加载共享库以便在流水线中使用库中的步骤、变量和类。这里的共享库是指在 Jenkins 实例中配置的、可以被多个 Jenkins 项目复用的代码库。\n解释一下这个语法：\n@Library('my-shared-library') 是一个指示器（directive），用于告诉 Jenkins 要加载命名为 my-shared-library 的共享库。这个名称对应于 Jenkins 配置中的共享库名称。 _ 是一个特殊的记号，用于加载库中定义的全局变量。当你使用这个记号时，它会自动加载共享库中名为 vars 目录下的所有 Groovy 脚本作为全局变量。这意味着这些脚本中定义的方法可以在 Jenkinsfile 中直接调用，而不需要任何 import 语句。 这个语法允许在 Jenkinsfile 中使用共享库提供的资源，而无需额外的导入步骤。实际上，这是一种 DSL（领域特定语言）层面的集成，它是 Jenkins 流水线插件提供的功能，不同于标准的 Groovy 语法。\n在共享库中，你可以定义步骤、全局变量或类。步骤通常定义在 vars 目录下，全局变量则可以在 vars 下直接定义，或者通过类定义在 src 目录下的包中。如果你想在 Jenkinsfile 中使用 src 目录下的类，你可能需要使用 import 语句，除非你使用了全局变量来包装这些类的功能。\n简而言之，@Library('my-shared-library') _ 这种写法是 Jenkins 流水线语法的一部分，它允许开发者以一种简洁的方式在 Jenkinsfile 中加载和使用共享库资源。\n","date":"18 November 2023","permalink":"/posts/2023/ci-cd/jenkins-ci/","section":"","summary":"入职之后，一直对公司的CI/CD流程实现细节一知半解，最近正好需要打包部署一个应用，借此机会一口气把所有黑盒给打开。","title":"Jenkins 进阶学习笔记"},{"content":"","date":"18 November 2023","permalink":"/tags/jenkinsfile/","section":"Tags","summary":"","title":"Jenkinsfile"},{"content":"","date":"12 November 2023","permalink":"/tags/ide/","section":"Tags","summary":"","title":"IDE"},{"content":"开个新坑，为了减少Hugo上传到仓库的图片大小，在插件市场看到个很符合我需求的东西： Learn Image 插件压缩图片，顺便来了兴趣系统地学习了解一下VS Code的整个配置和个性化。\nVisual Studio Code 教程 # VS Code是一个非常还用的编辑器，可以进行非常强大的自定义，具体参考： Visual Studio Code 官网教程\nVS Code Vim # 我一直对Vim编辑器有着一种独特的青睐，但苦于其学习成本和使用成本，投入了大量时间精力却没有得到什么回报。而 Vim for Visual Studio Code的出现，提供了一个很好的平衡。\nVS Code 的 Learn VIM 插件总结的很好：\nVisual Studio Code is superb. It offers an unparalleled user experience with great support for many languages and development ecosystem. It comes with great defaults and is super easy to use and get started with.\nVim is awesome. It modal nature and text editing features make it unique amongst other editors. Vim offers a complete different level of text editing proficiency, speed and accuracy from anything else out there.\nThe combination of both couldn\u0026rsquo;t be anything less than amazingly superbsome.\n代码提示快捷键 # 默认的Trigger代码提示快捷键：\nmac: cmd+space win: ctrl+space 都是非常容易和系统快捷键冲突的。所以需要修改。去VS Code修改快捷键的界面，输入Trigger Suggest可以找到当前的触发代码提示的快捷键。可以看到默认有几个，如果你觉得一个都不好用，就修改自定义。如果你习惯了cmd + i 或者ctrl + i等已有方案，就可以不用修改了。修改也很简单，点击前面的笔图标，直接在键盘输入你要设置的快捷键方式，然后按enter即可。\n","date":"12 November 2023","permalink":"/posts/2023/vscode-usage/","section":"","summary":"开个新坑，为了减少Hugo上传到仓库的图片大小，在插件市场看到个很符合我需求的东西： Learn Image 插件压缩图片，顺便来了兴趣系统地学习了解一下VS Code的整个配置和个性化。","title":"VS Code工具 使用记录"},{"content":"","date":"12 November 2023","permalink":"/tags/%E5%8D%9A%E5%AE%A2/","section":"Tags","summary":"","title":"博客"},{"content":"Three Pillars to Write Good HTML and CSS\u0026hellip; And Build Good Websites # Responsive Design Fluid layouts Media queries Responsive images Correct units Desktop-first v.s. mobile-first Maintainable and Scalable Code Clean Easy-to-understand Growth Reusable How to organize files How to name classes How to structure HTML Web Performance Less HTTP requests Less code Compress code Use a CSS preprocessor Less images Compress images 网页渲染过程 # 这部分也是很大的内容，我之前正好做过相关的笔记，哪天有空也放上来。下面是我学习时从各种博客上抄来的图片汇总：\nCSS Cascade(层叠) and Specificity(优先级) # 如果不想看视频，也可以直接阅读文档： Cascade, specificity, and inheritance。\nCSS的全程是什么？层叠样式表。这部分讲的是CSS的层叠规则。CSS的优先级可以从这几个角度区分。\nSource order Specificity Importance Source order # CSS可以通过\n行内样式（行间样式、内联样式、行嵌样式） 内部样式表 链入外部样式表 导入外部样式表 4种 CSS 引用方式。优先级总结就是就近原则，谁里元素近，谁就优先级高。\nImportance # 其中Importance部分优先级从高到低分别为：\n用户代理样式表中的 !important 声明 用户样式表中的 !important 声明 作者样式表中的 !important 声明 作者样式表中的常规声明（这些是我们 web 开发人员设置的样式） 用户样式表中的常规声明（由用户设置的自定义样式） 用户代理样式表中的声明（例如，浏览器的默认样式，在没有设置其他样式时使用） Google Chrome Dev Tools 中修改的也是作者样式表。\n阅读更多：\nhttps://juejin.cn/post/7225634879151849509 https://juejin.cn/post/6926822995142918152 什么是用户代理样式表 # 用户代理（User Agent，通常指浏览器）为HTML元素提供了一组默认的样式。这些样式在没有任何外部样式表的情况下应用于网页，以确保即使在没有CSS的情况下，网页内容依然具有基本的可读性和可访问性。用户代理样式因浏览器而异，通常包括基本的字体、颜色、边距等设置。\n什么是用户样式表 # 用户样式表是由用户自定义的样式表，可以用于覆盖用户代理样式和作者样式表中的某些样式。用户可以根据自己的偏好设置用户样式表，例如调整字体大小、颜色等。用户样式表主要用于改善网页的可访问性和可用性，满足个别用户的特殊需求。在现代浏览器中，用户可以通过安装扩展或修改浏览器设置来应用自定义的用户样式表。\n什么是作者样式表 # 作者样式表是由网页开发者创建的样式表，用于定义网页的布局、外观和交互。作者样式表通常是网页设计的主要组成部分，它可以覆盖用户代理样式和用户样式表中的样式。作者样式表可以包含内联样式、嵌入式样式和外部样式表，以及通过@import引入的其他样式表。\n选择器优先级（Specificity） # 选择器有很多种，元素选择器，类选择器，ID选择器，属性选择器，伪类选择器，伪元素选择器，组合选择器。\n那怎么计算层叠最后的结果呢？其实就是给不同的选择器赋予不同的权重，最后累计求和，值越大优先级越高。当多个选择器应用于同一元素时，具有较高特指性的选择器将覆盖较低特指性的选择器。\n内联样式的权重为 1000 ID选择器的权重为 100 类选择器、属性选择器和伪类的权重为 10 元素选择器和伪元素的权重为 1 例子 # 下面的例子，最后的四元组就是对应类型选择器的数量，与对应的权重相乘后相加即可得到最高优先级。（或者我们可以直接从高到低比较大小）\n再看这个例子：\n#nav div.pull-right a.buttom{ background-color: red; } #nav a.button:hover{ background-color: yellow; } 如果这两个组合选择器都指向同一个元素，那最后哪个会生效呢？我之前存在一个误区，认为:hover这种行为的时候，肯定是下面的选择器生效，会变成yellow，但实际上:hover是伪类，也是通过优先级计算的，优先级权重是10，但前者的权重结果是：100+10+1 \u0026gt; 后者的结果100+10，所以即使鼠标移动到该元素上，也还是红色。\nCSS Value Processing # 相对大小转换为绝对大小 # CSS Value Processing： What You Need To Know # 每个属性都有默认值，used if nothing is declared 浏览器为每个页面声明了一个默认的root font-size 百分比和相对大小总是会换算为绝对大小 。。。翻译半天，感觉还不如直接看原文。\nhello world: 310 hello world: 239\n","date":"8 November 2023","permalink":"/posts/2023/frontend/advanced-css-study-notes/section-ii/","section":"","summary":"Three Pillars to Write Good HTML and CSS\u0026hellip; And Build Good Websites # Responsive Design Fluid layouts Media queries Responsive images Correct units Desktop-first v.","title":"Advanced Css Study Notes Section II"},{"content":"","date":"8 November 2023","permalink":"/tags/css/","section":"Tags","summary":"","title":"CSS"},{"content":"","date":"8 November 2023","permalink":"/tags/sass/","section":"Tags","summary":"","title":"Sass"},{"content":"","date":"8 November 2023","permalink":"/series/%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/","section":"Series","summary":"","title":"前端基础从入门到入土"},{"content":"","date":"8 November 2023","permalink":"/tags/%E5%AD%A6%E4%B9%A0/","section":"Tags","summary":"","title":"学习"},{"content":"","date":"8 November 2023","permalink":"/tags/%E7%AC%94%E8%AE%B0/","section":"Tags","summary":"","title":"笔记"},{"content":"我的 Udemy排名第一的高级CSS课程 Advanced CSS and Sass - 高级 CSS 和 Sass：Flexbox、网格、动画（中英文字幕）笔记。\n想要系统学习CSS， mdn web docs会是不错的文档。\nfont-family # 可以通过在html的header中引入字体然后\nbody { font-family: \u0026#39;Long Cang\u0026#39;, cursive, Georgia, \u0026#39;Times New Roman\u0026#39;, Times, serif; font-weight: 400; font-size: 16px; line-height: 1.7; color: #777; } 这样使用。\n注意font-family这行的语法，是优先级从高到低的字体列表。每一个css字段似乎都有这样的规则，我这样写也是不会抱错的：\nfont-size: 16px, 18px, 20px; 因为是优先级从高到低的列表，那我就可以：\nbackground-image: linear-gradient(to right bottom, rgba(128, 214, 113, 0.8), rgba(39, 180, 133, 0.8)), url(../img/hero.jpg); 有点像图层，上层是渐变色，下层是图片。\ncss 函数 # 许多 CSS 属性 将 URL 作为属性值，例如 background-image、cursor、@font-face、list-style 等。 url()\nlinear-gradient()\npx 和 vh # 绝对大小和相对大小单位\ndiv 和 行内元素 # div 可以看作一个容器，把行内元素包在容器里。算是一个小的tips吧。\nposition # position有static， relative, absolute, fixed，sticky\u0026hellip;默认position为static，也就是该关键字指定元素使用正常的布局行为，即元素在文档常规流中当前的布局位置。此时 top, right, bottom, left 和 z-index 属性无效。\nabsolute 和 relative # 课程中，老师在\u0026lt;div class=\u0026quot;logo-box\u0026quot;\u0026gt;设置为absolute定位时，特意跑回父元素\u0026lt;header class=\u0026quot;header\u0026quot;\u0026gt;设置为relative定位，很好奇是为什么，然后就搜到了以下知识点：\nCSS 中，为什么绝对定位（absolute）的父级元素必须是相对定位（relative）？ - 丁小倪的回答 - 知乎\n首先，我想告诉你的是，如果父级元素是绝对定位（absolute）或者没有设置，里面的绝对定位（absolute）自动以body定位。这句话是错的。正确的是：只要父级元素设了position并且不是static（默认既是static），那么设定了absolute的子元素即以此为包含块（最近的）。绝对定位（Absolute positioning）元素定位的参照物是其包含块，既相对于其包含块进行定位，不一定是其父元素。建议去详细通读一下定位体系和包含块。\n\u0026lt;img\u0026gt; height # 参考自： HTML 标签的 height 和 width 属性\n图像预留空间 # 为图像指定 height 和 width 属性是一个好习惯。如果设置了这些属性，就可以在页面加载时为图像预留空间。如果没有这些属性，浏览器就无法了解图像的尺寸，也就无法为图像保留合适的空间，因此当图像加载时，页面的布局就会发生变化。（下面的篇幅详细解释了这个观点）。\n改变图像大小 - 制作填充图像 # height 和 width 属性有一种隐藏的特性，就是人们无需指定图像的实际大小，也就是说，这两个值可以比实际的尺寸大一些或小一些。浏览器会自动调整图像，使其适应这个预留空间的大小。使用这种方法就可以很容易地为大图像创建其缩略图，以及放大很小的图像。但需要注意的是：浏览器还是必须要下载整个文件，不管它最终显示的尺寸到底是多大，而且，如果没有保持其原来的宽度和高度比例，图像会发生扭曲。\nand # HTML \u0026lt;span\u0026gt; 元素是短语内容的通用行内容器，并没有任何特殊语义。可以使用它来编组元素以达到某种样式意图（通过使用类或者 Id 属性），或者这些元素有着共同的属性，比如lang。应该在没有其他合适的语义元素时才使用它。\u0026lt;span\u0026gt; 与 \u0026lt;div\u0026gt; 元素很相似，但 \u0026lt;div\u0026gt; 是一个 块元素 而 \u0026lt;span\u0026gt; 则是 行内元素 (en-US).\n区别 # Stack Overflow 上有人提出了类似的问题： whats-the-different-between-div-and-span-if-i-set-display-block-or-inline\n答案是：\u0026lt;div\u0026gt;里可以放\u0026lt;span\u0026gt;,但是\u0026lt;span\u0026gt;里不可以放\u0026lt;div\u0026gt;。\ndisplay # CSS display 属性设置元素是否被视为块或者内联元素以及用于子元素的布局，例如流式布局、网格布局或弹性布局。\n形式上，display 属性设置元素的内部和外部的显示类型。外部类型设置元素参与流式布局；内部类型设置子元素的布局。一些 display 值在它们自己的单独规范中完整定义；例如，在 CSS 弹性盒模型的规范中，定义了声明 display: flex 时会发生的细节。\n注意 # 形式上，display 属性设置元素的内部和外部的显示类型。（这是我之前漏掉的很重要的一部分，所以着重强调一下）\n外部表现 # 这些关键字规定元素的外部显示类型，实际上就是其在流式布局中的角色：\nblock # 该元素生成一个块级元素盒，在正常的流中，该元素之前和之后产生换行。\ninline # 该元素生成一个或多个内联元素盒，它们之前或者之后并不会产生换行。在正常的流中，如果有空间，下一个元素将会在同一行上。\n内部表现 # 这些关键字规定了元素的内部显示类型，其定义了该内容布局时的格式上下文的类型（假设它是一个非替换元素）：\nflow 实验性 # 该元素使用流式布局（块和内联布局）来排布它的内容。\n如果它的外部显示类型是 inline 或 run-in，并且它参与一个块或者内联格式上下文，那么它将生成一个内联盒子。否则它将生成一个块容器盒。\n根据其他属性的值（例如 position、float 或 overflow）以及它自身是否参与到块或者内联格式化上下文，它要么为它的内容建立新的块级格式化上下文（BFC），要么将其内容集成到其父元素的格式化上下文中。\nflow-root # 该元素生成一个块级元素盒，其会建立一个新的块级格式化上下文，定义格式化上下文的根元素。\ntable # 该元素的行为类似于 HTML 中的 元素。它定义了一个块级别的盒子。\nflex # 该元素的行为类似块级元素并且根据弹性盒模型布局它的内容。\ngrid # 该元素的行为类似块级元素并且根据网格模型布局它的内容。\ntext-transform # text-transform CSS 属性指定如何将元素的文本大写。它可以用于使文本显示为全大写或全小写，也可单独对每一个单词进行操作。\n也就是说，除了通过JS来设置显示内容的大小写之外，通过CSS也能实现。\ntransform # CSS transform 属性允许你旋转，缩放，倾斜或平移给定元素。这是通过修改 CSS 视觉格式化模型的坐标空间来实现的。\n在教程中的用法非常具有参考性，不借助flex等display要将某一子元素相对父元素中心居中，应该怎么办呢？\n.text-box{ position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); } 重点是：transform: translate(-50%, -50%);。\n阅读 transform-function发现，元素左上角是坐标原点，translate(-50%, -50%)相当于向左和向上平移一般，那原来的\n.text-box{ position: absolute; top: 50%; left: 50%; } 是将父元素的左上角固定在距视图top: 50%; left: 50%;的位置，是父元素的左上角居中。使用translate(-50%, -50%)平移子元素后，子元素的中心居中。\n@keyframes # 才知道有 @keyframes这么强大的功能！\n关键帧 @keyframes at-rule 规则通过在动画序列中定义关键帧（或 waypoints）的样式来控制 CSS 动画序列中的中间步骤。和 转换 transition 相比，关键帧 keyframes 可以控制动画序列的中间步骤。\n首先在css中定义关键帧，\n@keyframes moveInLeft{ 0% { opacity: 0; transform: translateX(-100px) rotate(0deg); } 60%{ transform: rotate(60deg); } 80%{ transform: translateX(10px); } 100%{ opacity: 1; transform: translateX(0); } } 然后使用关键帧，类似这样：\n.heading-primary-main{ display: block; font-size: 80px; font-weight: 400; letter-spacing: 35px; animation-name: moveInLeft; animation-duration: 1s; animation-timing-function: ease-in; } 或者缩写为:\nanimation: moveInRight 1s ease-out; 这里是关于 animation-timing-function的介绍，简而言之就是决定是平滑过渡还是怎么过渡。\n伪类(Pseudo-classes) # CSS 伪类是添加到选择器的关键字，用于指定所选元素的特殊状态。例如，伪类 :hover 可以用于选择一个按钮，当用户的指针悬停在按钮上时，设置此按钮的样式。\n比如指针悬浮效果：\nbutton:hover { color: blue; } 又非常多的伪类，非常有用。\ndisplay: inline-block # 尽管刚熟悉了inline和block，但是看到这里还是有点迷惑。重点学习一下。\n与 display: inline 相比，主要区别在于 display: inline-block 允许在元素上设置宽度和高度。\n同样，如果设置了 display: inline-block，将保留上下外边距/内边距，而 display: inline 则不会。\n与 display: block 相比，主要区别在于 display：inline-block 在元素之后不添加换行符，因此该元素可以位于其他元素旁边。\ntext-align # 除了之前的transform让元素居中外，还有什么更简单的方法吗？text-align CSS 属性设置块元素或者单元格框的行内内容的水平对齐。\ntext-align属性是用来描述一个行内元素是如何在身为父元素的块级元素中对齐。\n通过定义可以看出text-align属性并不能控制块级元素的对齐方式，它只对块级元素内的行内元素生效。\n所以\n\u0026lt;div class=\u0026#34;text-box\u0026#34;\u0026gt; \u0026lt;h1 class=\u0026#34;heading-primary\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;heading-primary-main\u0026#34;\u0026gt;Outdoors\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;heading-primary-sub\u0026#34;\u0026gt;is where life happens\u0026lt;/span\u0026gt; \u0026lt;/h1\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;btn btn-white\u0026#34;\u0026gt;Discover Our Tours\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; 中，要想\u0026lt;a href=\u0026quot;#\u0026quot; class=\u0026quot;btn btn-white\u0026quot;\u0026gt;Discover Our Tours\u0026lt;/a\u0026gt;水平居中很简单，只要在它或者它的父元素上声明text-align: center即可。\nbox-shadow # CSS box-shadow 属性用于在元素的框架上添加阴影效果。你可以在同一个元素上设置多个阴影效果，并用逗号将他们分隔开。该属性可设置的值包括阴影的 X 轴偏移量、Y 轴偏移量、模糊半径、扩散半径和颜色。\n这个相对好理解。\n伪元素(Pseudo-elements) # 注意区分 伪类 和 伪元素！一个是一个冒号，一个是两个冒号。\n伪元素是一个附加至选择器末的关键词，允许你对被选择元素的特定部分修改样式。\n比如伪类中的:hover是指当前元素在鼠标悬浮时的状态，而伪元素是选中被选择元素的特定部分。\n::after (:after) # CSS伪元素 ::after用来创建一个伪元素，作为已选中元素的最后一个子元素。通常会配合content属性来为该元素添加装饰内容。这个虚拟元素默认是行内元素。\n不太好理解，还是需要结合教程中的代码理解。\nz-index # CSS z-index 属性设置定位元素及其后代元素或 flex 项目的 Z 轴顺序。z-index 较大的重叠元素会覆盖较小的元素。\n这个MDN的示例非常清晰，就是控制图层的覆盖的。当Z-index的值设置为一个整数时,该整数是当前堆叠上下文中生成的div的堆栈级别。数字越小，越靠前。\n注意 # 只有position的值为relative/absolute/fixed中的一个,Z-index才会生效。\nanimation-fill-mode # CSS 属性 animation-fill-mode 设置 CSS 动画在执行之前和之后如何将样式应用于其目标。\nanimation-fill-mode也是一个非常有用的属性，也就是确定动画播放前和播放后的状态。\n","date":"7 November 2023","permalink":"/posts/2023/frontend/advanced-css-study-notes/section-i/","section":"","summary":"我的 Udemy排名第一的高级CSS课程 Advanced CSS and Sass - 高级 CSS 和 Sass：Flexbox、网格、动画（中英文字幕）笔记。","title":"Advanced CSS Study Notes Section I"},{"content":"人生列车缓慢地行驶在阳光明媚的午后旷野。若有人向我招手，我便邀请他们坐上一段，听他们分享关于面包，远方和在夜晚流浪的一切，最后微笑着告别。\n","date":"6 November 2023","permalink":"/diary/2023/2023-11-1-friends/","section":"","summary":"人生列车缓慢地行驶在阳光明媚的午后旷野。若有人向我招手，我便邀请他们坐上一段，听他们分享关于面包，远方和在夜晚流浪的一切，最后微笑着告别。","title":"午后旷野"},{"content":"官方文档 # elastic organization github homepage APM Agents Legacy APM Server Elasticsearch Kibana APM Real User Monitoring JavaScript Agent(Angular integration) Run APM Server on Docker docker-elk 模板 传统的安装部分可以跳过，因为现在一般都是安装在docker上，我们可以直接使用官方或者第三方已经写好的dockerfile等文件替代传统的安装方式。\n介绍 # Q: What is APM? # A: Free and open application performance monitoring\nElastic APM is an application performance monitoring system built on the Elastic Stack. It allows you to monitor software services and applications in real-time, by collecting detailed performance information on response time for incoming requests, database queries, calls to caches, external HTTP requests, and more. This makes it easy to pinpoint and fix performance problems quickly. Elastic APM also automatically collects unhandled errors and exceptions. Errors are grouped based primarily on the stack trace, so you can identify new errors as they appear and keep an eye on how many times specific errors happen. Metrics are another vital source of information when debugging production systems. Elastic APM agents automatically pick up basic host-level metrics and agent-specific metrics, like JVM metrics in the Java Agent, and Go runtime metrics in the Go Agent.\nAPM Server # APM Server是elastic家推出的前端性能监控方案的组成部分。它接收从Elastic APM agents发送来的信息并转发到Elasticsearch documents中存储，最后在Kibana中进行性能指标的可视化。\ninstall Prerequisite # apm-server 依赖 elk, 所以在安装apm-server之前至少要安装 elastic search 和 kibana。elastic官方提供了elk镜像，我们可以非常快捷地通过docker进行安装。docker-compose.yml的主要结构如下：\nversion: \u0026#34;3\u0026#34; services: elasticsearch: image: elasticsearch:${ELK_VERSION} ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; networks: - elk kibana: image: kibana:${ELK_VERSION} ports: - \u0026#34;5601:5601\u0026#34; depends_on: - elasticsearch networks: - elk apm-server: image: elastic/apm-server:${ELK_VERSION} ports: - \u0026#34;8200:8200\u0026#34; depends_on: - elasticsearch networks: - elk networks: elk: driver: bridge 其中变量声明在了.env文件中,版本可以自己指定,但不能是latest，必须指定:\nELK_VERSION=8.11.0 除此之外很重要的一部分就是进行ELK的配置。 On the other hand, 如果就按上面的配置，然后docker-compose up启动然后访问localhost:5601已经可以访问到如下界面： 点击Where do I find this?，可以看到：\nThe enrollment token is automatically generated when you start Elasticsearch for the first time. You might need to scroll back a bit in the terminal to view it.\nTo generate a new enrollment token, run the following command from the Elasticsearch installation directory:\nbin/elasticsearch-create-enrollment-token --scope kibana\n所以进入Elasticsearch容器的/usr/share/elasticsearch目录，执行上述命令即可。然后复制生成的token，输入后进入下一步，Verification required: Copy the code from the Kibana server or run bin/kibana-verification-code to retrieve it.\n所以按照指示，进入kibana容器的/usr/share/kibana目录，执行上述命令，填入生成的验证码即可。若上述步骤没有问题，接下来就会来到登录界面：\nbuilt-user # 官网有介绍内建用户的文章： Built-in users\nelastic\nA built-in superuser.\nkibana_system\nThe user Kibana uses to connect and communicate with Elasticsearch.\nlogstash_system\nThe user Logstash uses when storing monitoring information in Elasticsearch.\nbeats_system\nThe user the Beats use when storing monitoring information in Elasticsearch.\napm_system\nThe user the APM server uses when storing monitoring information in Elasticsearch.\nremote_monitoring_user\n鉴权注意 # 一 # Starting with Elastic v8.0.0, it is no longer possible to run Kibana using the bootstraped privileged elastic user.\n也就是说。自从v8开始，不能使用使用默认密码的超级用户elastic登录kibana了，要想用elastic用户登录需要先修改elastic用户的密码。\n二 # Elasticsearch 从 6.8 开始， 允许免费用户使用 X-Pack 的安全功能，且默认开启。如果不开启，许多功能无法使用，比如如果不开启，kibana 现在是没办法连接到 elastic search的，老用户不要觉得下面的设置麻烦而直接xpack.security.enabled=false关闭安全特性。可以说，这是必须开启的。\nWARN LOG # 可能会遇到 Elasticsearch showing received plaintext http traffic on an https channel in console问题。\n修改密码 # 有三种修改密码的方式。\n方法一、启动前修改配置文件 # 在.env文件里添加变量：\nELASTIC_PASSWORD=your_password_here 然后docker-compose.yml里配置环境变量映射到elastic search的配置文件里：\nversion: \u0026#34;3\u0026#34; services: elasticsearch: image: elasticsearch:${ELK_VERSION} ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; environment: # \u0026#34;:-\u0026#34; 表示使用默认值。具体来说，这个语法表示如果ELASTIC_PASSWORD已经定义了，那么使用它的值；如果没有定义，那么就使用默认值，这里的默认值是空。 ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-} networks: - elk 然后docker-compose up重新启动即可，输入elastic和修改后的密码即可登录成功。\n方法二、命令行修改 # elastic search 安装目录的 /bin 文件夹里有很多工具，其中就包括设置以及修改密码的工具。\n设置密码 # sh-5.0$ bin/elasticsearch-setup-passwords interactive ****************************************************************************** Note: The \u0026#39;elasticsearch-setup-passwords\u0026#39; tool has been deprecated. This command will be removed in a future release. ****************************************************************************** Initiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N] 修改密码 # sh-5.0$ bin/elasticsearch-reset-password --interactive -u elastic This tool will reset the password of the [elastic] user. You will be prompted to enter the password. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Re-enter password for [elastic]: Password for the [elastic] user successfully reset. 新增用户 # sh-5.0$ elasticsearch-users -h Manages elasticsearch file users Commands -------- useradd - Adds a file user userdel - Deletes a file based user passwd - Changes the password of an existing file based user roles - Edit roles of an existing user list - List existing file based users and their corresponding roles Non-option arguments: command Option Description ------ ----------- -E \u0026lt;KeyValuePair\u0026gt; Configure a setting -h, --help Show help -s, --silent Show minimal output -v, --verbose Show verbose output sh-5.0$ elasticsearch-users useradd esadmin Enter new password: Retype new password: 权限控制 # 查看上面的输出，可以看到该命令还能删除用户，编辑权限等：\nsh-5.0$ elasticsearch-users roles -h Edit roles of an existing user The roles command allows editing roles for file based users. You can also list a user\u0026#39;s roles by omitting the -a and -r parameters. Non-option arguments: username Option Description ------ ----------- -E \u0026lt;KeyValuePair\u0026gt; Configure a setting -a, --add Adds supplied roles to the specified user (default: ) -h, --help Show help -r, --remove Remove supplied roles from the specified user (default: ) -s, --silent Show minimal output -v, --verbose Show verbose output 比如我刚创建的esadmin用户现在还不能登录kibana： 添加下列权限后就可以成功登录了。（具体权限查看 Built-in roles）\nsh-5.0$ elasticsearch-users roles -a kibana_system esadmin sh-5.0$ elasticsearch-users roles -a superuser esadmin 查看权限：\nsh-5.0$ elasticsearch-users roles -v esadmin esadmin : kibana_system,superuser 这一部分非常感谢这篇博客 ELK Kibana 8.3.2登录认证, 我是从这篇博客了解到该知识并顺藤摸瓜摸到官方文档的。\n方法二、es api修改 # 这部分也是从 docker中设置elasticsearch、kibana用户名密码、修改密码受到的启发。\n在kibana的Dev Tools Console修改 # 要想使用该方法，需要先了解curl(client url)的简单用法，参考： 阮一峰老师的博客。\n修改密码的API参考： Change passwords API\n比如：\nPOST /_security/user/elastic/_password { \u0026#34;password\u0026#34; : \u0026#34;helloworld\u0026#34; } 或者还可以在终端通过curl直接修改。\n终端curl修改 # curl -XPOST -D- \u0026#39;http://localhost:9200/_security/user/esadmin/_password\u0026#39; \\ -H \u0026#39;Content-Type: application/json\u0026#39; \\ -u elastic:helloworld \\ -d \u0026#39;{\u0026#34;password\u0026#34; : \u0026#34;helloworldagain\u0026#34;}\u0026#39; 看起来是没问题的，但好像是安全问题，返回:curl: (52) Empty reply from server。暂时不研究了，如果有人知道是为什么可以告诉我。\nTL;DR; # 最终的最简单的配置：\n.env # ELK_VERSION=8.11.0 ELASTIC_PASSWORD=\u0026#39;changeme\u0026#39; KIBANA_SYSTEM_PASSWORD=\u0026#39;changeme\u0026#39; APM_SYSTEM_PASSWORD=\u0026#39;changeme\u0026#39; docker-compose.yml # version: \u0026#34;3\u0026#34; services: elasticsearch: image: elasticsearch:${ELK_VERSION} ports: - \u0026#34;9200:9200\u0026#34; - \u0026#34;9300:9300\u0026#34; environment: # \u0026#34;:-\u0026#34; 表示使用默认值。具体来说，这个语法表示如果ELASTIC_PASSWORD已经定义了，那么使用它的值；如果没有定义，那么就使用默认值，这里的默认值是空。 - ELASTIC_PASSWORD:${ELASTIC_PASSWORD:-} networks: - elk kibana: image: kibana:${ELK_VERSION} ports: - \u0026#34;5601:5601\u0026#34; environment: - KIBANA_SYSTEM_PASSWORD:${KIBANA_SYSTEM_PASSWORD:-} - I18N_LOCALE:zh-CN depends_on: - elasticsearch networks: - elk apm-server: image: elastic/apm-server:${ELK_VERSION} ports: - \u0026#34;8200:8200\u0026#34; environment: - APM_SYSTEM_PASSWORD:${APM_SYSTEM_PASSWORD:-} depends_on: - elasticsearch networks: - elk networks: elk: driver: bridge 安装APM插件 # https://www.elastic.co/guide/en/apm/guide/current/configuration-rum.html\nhttps://www.elastic.co/guide/en/apm/agent/rum-js/current/angular-integration.html\nhttps://www.elastic.co/guide/en/elasticsearch/reference/8.1/service-accounts.html\n最后的apm-server.yml:\napm-server: host: apm-server:8200 frontend.enabled: true frontend.allow_origins: \u0026#34;*\u0026#34; rum: enabled: true allow_origins: [\u0026#39;*\u0026#39;] allow_headers: [\u0026#34;header1\u0026#34;, \u0026#34;header2\u0026#34;] library_pattern: \u0026#34;node_modules|bower_components|~\u0026#34; exclude_from_grouping: \u0026#34;^/webpack\u0026#34; auth: anonymous: rate_limit.event_limit: 300 rate_limit.ip_limit: 1000 allow_service: [\u0026#39;my-service-name\u0026#39;, \u0026#39;hello-world\u0026#39;] output.elasticsearch: enabled: true hosts: [\u0026#34;elasticsearch:9200\u0026#34;] username: \u0026#34;logadmin\u0026#34; password: \u0026#34;123456\u0026#34; setup.kibana: host: \u0026#34;kibana\u0026#34; username: \u0026#34;logadmin\u0026#34; password: \u0026#34;123456\u0026#34; Source Map # https://www.elastic.co/guide/en/apm/guide/current/source-map-how-to.html\nhttps://angular.cn/guide/workspace-config#complex-configuration-values\n","date":"6 November 2023","permalink":"/posts/2023/frontend/frontend_performance_monotor/","section":"","summary":"官方文档 # elastic organization github homepage APM Agents Legacy APM Server Elasticsearch Kibana APM Real User Monitoring JavaScript Agent(Angular integration) Run APM Server on Docker docker-elk 模板 传统的安装部分可以跳过，因为现在一般都是安装在docker上，我们可以直接使用官方或者第三方已经写好的dockerfile等文件替代传统的安装方式。","title":"Docker安装APM Server"},{"content":"","date":"6 November 2023","permalink":"/tags/elastic-search/","section":"Tags","summary":"","title":"Elastic Search"},{"content":"","date":"6 November 2023","permalink":"/tags/elk/","section":"Tags","summary":"","title":"ELK"},{"content":"","date":"6 November 2023","permalink":"/series/%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/","section":"Series","summary":"","title":"前端性能监控"},{"content":"","date":"6 November 2023","permalink":"/tags/%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/","section":"Tags","summary":"","title":"性能监控"},{"content":"","date":"6 November 2023","permalink":"/tags/npm/","section":"Tags","summary":"","title":"Npm"},{"content":"参考文档 # 什么是 npm —— 写给初学者的编程教程 npm docs npm 和 npx 的区别是什么 package.json 详解 package.json 自定义字段 npx 使用教程 npm scripts 使用指南 npm # npm是node.js中的包管理器，npm 使 JavaScript 开发人员可以快速方便地共享软件包。\nnpm 由两个主要部分组成:\n用于发布和下载程序包的 CLI（命令行界面）工具 托管 JavaScript 程序包的在线存储库 npm 本身并不运行任何软件包。如果你想使用 npm 运行一个包，你必须在 package.json 文件中指定这个包。\n当可执行文件通过 npm 包安装时，npm 会创建链接指向它们。这些包不是安装为全局可执行文件，而是安装在：\n本地安装的链接是在 ./node_modules/.bin/ 目录下创建的 全局安装会在全局 bin/ 目录下创建链接（例如：Linux 上的 /usr/local/bin 或 Windows 上的 %AppData%/npm） 要用 npm 执行一个包，你必须输入本地路径,比如要执行刚npm install prettier安装的prettier来美化代码，你需要：\n./node_modules/.bin/prettier 。 --check 或者通过在脚本部分的 package.json 文件中添加一个本地安装的软件包来运行它:\n{ \u0026#34;name\u0026#34;: \u0026#34;your-application\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;prettier-code\u0026#34;: \u0026#34;prettier . --write\u0026#34; } } 然后用npm run prettier-code来运行这个脚本。\nnpx # 主要功能 # npx 想要解决的主要问题，就是调用项目内部安装的模块。\n还是以上文的prettier为例，\n./node_modules/.bin/prettier . --check 现在只需要写成\nnpx prettier . --check npx 的原理很简单，就是运行的时候，会到node_modules/.bin路径和环境变量$PATH里面，检查命令是否存在。 由于 npx 会检查环境变量$PATH，所以系统命令也可以调用。\nnpx ls 就等于 ls。\n执行未安装的软件包 # 如果只想使用一次某些软件包（不管是出于测试还是什么目的），那么你没有必要本地全局安装。npx可以实现把该软件包下载到一个临时的目录，执行完成就删除软件包，降低磁盘占用。\nnpx的这一功能 使测试一个 Node.js 包或模块的不同版本变得非常容易。（不过我暂时没有什么使用场景）\npackage.json # 每个 JavaScript 项目（无论是 Node.js 还是浏览器应用程序）都可以被当作 npm 软件包，并且通过 package.json 来描述项目和软件包信息。当运行 npm init 初始化 JavaScript/Node.js 项目时，将生成 package.json 文件。\n项目的 package.json 是配置和描述如何与程序交互和运行的中心。 npm CLI（和 yarn）用它来识别你的项目并了解如何处理项目的依赖关系。package.json 文件使 npm 可以启动你的项目、运行脚本、安装依赖项、发布到 NPM 注册表以及许多其他有用的任务。 npm CLI 也是管理 package.json 的最佳方法，因为它有助于在项目的整个生命周期内生成和更新 package.json 文件。\npackage.json里有很多字段，如果需要的时候最好的办法还是查阅官方文档： Specifics of npm\u0026rsquo;s package.json handling。\n我这里记录一下几个我觉得很常用的部分。\nmain # { \u0026#34;main\u0026#34;: \u0026#34;src/index.js\u0026#34;, } The main field is a module ID that is the primary entry point to your program. That is, if your package is named foo, and a user installs it, and then does require(\u0026ldquo;foo\u0026rdquo;), then your main module\u0026rsquo;s exports object will be returned. This should be a module relative to the root of your package folder.\n也就是说，main字段定义了项目的入口点，当导入此包的时候，main指定的入口文件中的module.exports中的内容会被返回。\nscripts # The \u0026ldquo;scripts\u0026rdquo; property of your package.json file supports a number of built-in scripts and their preset life cycle events as well as arbitrary scripts. These all can be executed by running npm run-script \u0026lt;stage\u0026gt; or npm run \u0026lt;stage\u0026gt; for short.\nnpm默认提供了一些脚本和生命周期钩子，不过我们完全可以修改以及创建自定义的脚本。\nnpm脚本实际上就是shell脚本，每当执行npm run，就会自动新建一个 Shell，在这个 Shell 里面执行指定的脚本命令。\nLife Cycle Scripts # npm 脚本有pre和post两个钩子。举例来说，build脚本命令的钩子就是prebuild和postbuild。\n{ \u0026#34;scripts\u0026#34;:{ \u0026#34;prebuild\u0026#34;: \u0026#34;echo I run before the build script\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;cross-env NODE_ENV=production webpack\u0026#34;, \u0026#34;postbuild\u0026#34;: \u0026#34;echo I run after the build script\u0026#34; } } 用户执行npm run build的时候，会自动按照下面的顺序执行。\nnpm run prebuild \u0026amp;\u0026amp; npm run build \u0026amp;\u0026amp; npm run postbuild\n创建自定义脚本 # { \u0026#34;scripts\u0026#34;:{ \u0026#34;prepare\u0026#34;: \u0026#34;husky install\u0026#34; } } dependencies # 这是 package.json 中最重要的字段之一，它列出了项目使用的所有依赖项（项目所依赖的外部代码）。\ndevDependencies # 与 dependencies 字段类似，但是这里列出的包仅在开发期间需要，而在生产中不需要。再生产环境中可以通过npm install --production来减少安装包体积。\npeerDependencies, overrides\u0026hellip; # 还有很多字段，也是非常实用的。但这部分一般遇不到，你只需要遇到的时候知道怎么搜索对应的关键字即可。\n自定义字段 # 在 package.json 文件中，还可以自定义字段（这些字段不会影响到 npm 对包的处理，主要是用来存储信息，特定的软件包可以读取）。\n要自定义字段，只需要在 package.json 文件中添加新的键值对即可。\n{ \u0026#34;name\u0026#34;: \u0026#34;angular-love-pdf\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.0\u0026#34;, \u0026#34;lint-staged\u0026#34;: { \u0026#34;**/*\u0026#34;: \u0026#34;prettier --write --ignore-unknown\u0026#34; }, } 总结 # 我觉得想学习JavaScript的工程化应用，首先必须学会使用npm和packages.json。通过这篇文章，我也加深了自己对这些概念的理解。\n","date":"6 November 2023","permalink":"/posts/2023/frontend/npx_vs_npm/","section":"","summary":"参考文档 # 什么是 npm —— 写给初学者的编程教程 npm docs npm 和 npx 的区别是什么 package.","title":"npm，npx和packages.json"},{"content":"","date":"6 November 2023","permalink":"/tags/npx/","section":"Tags","summary":"","title":"Npx"},{"content":"前言 # 如果你逛Github的话，就会发现很多项目根目录除了.github还有个.husky文件夹，我一直好奇这个文件夹的作用。今天正好创建了一个新项目，借此机会一探究竟。\n项目地址 # husky prettier lint-staged eslint commitlint 了解Git Hooks # Git Hooks 是在 Git 执行特定事件（如commit、push、receive等）时触发运行的脚本（也就是Shell，Python等语言都可以），类似于“钩子函数”。跟钩子函数一样，Git Hooks可以起到一个承上启下的作用。\nGit Hooks是Git提供的特性。钩子都被存储在 Git 目录下的 hooks 子目录中。 也即绝大部分项目中的 .git/hooks 。 当你用 git init 初始化一个新版本库时，Git 默认会在这个目录中放置一些示例脚本。钩子又可以分类为客户端钩子和服务器端钩子。客户端钩子分为很多种。 下面把它们分为：提交工作流钩子、电子邮件工作流钩子和其它钩子。如果想了解更多关于Git Hooks的细节，请参考 Git官方文档（Git 钩子）\nGit Hooks存在的问题 # 由于Git Hooks默认是存在.git目录下的，无法进行版本控制。好在Git新版本中core.hooksPath的出现可以使Hooks存放的路径指向自定义的目录。\nhusky # 为什么需要在git hooks上再多husky这个上层建筑呢？简而言之，它能够简化创建和修改Githooks的操作。\n安装husky # 根据 husky官方文档，\nnpx husky-init \u0026amp;\u0026amp; npm install 它会：\n添加prepare脚本到package.json 创建一个模板pre-commit钩子 配置Git hooks路径到.husky 自定义钩子 # 以下命令会创建一个pre-commitgit hook，也就是在每次commit之前都会执行npm test,如果执行失败呢，就不会commit成功。\nnpx husky add .husky/pre-commit \u0026#34;npm test\u0026#34; （如果不清楚npm和npx的区别，请参考我的另一篇文章： npm 和 npx 是什么）\nprettier # Prettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary.\n简而言之，Prettier 是一个代码美化工具。支持JavaScript · TypeScript · Flow · JSX · JSON · CSS · SCSS · Less · HTML · Vue · Angular · GraphQL · Markdown · YAML等语言。\n安装prettier # 同样，参考自 官方文档。\nnpm install --save-dev --save-exact prettier 然后执行下列命令会在根目录新建一个空的prettier配置文件。\nnode --eval \u0026#34;fs.writeFileSync(\u0026#39;.prettierrc\u0026#39;,\u0026#39;{}\\n\u0026#39;)\u0026#34; CLI使用 # 主要有两个操作：\ncheck（检查文件是否符合代码风格，但不执行格式化） write（格式化文件） check # 这里的.是指当前目录，可以自己指定想要格式化的目录。\nnpx prettier . --check write # 这里的.是指当前目录，可以自己指定想要格式化的目录。\nnpx prettier . --write 与编辑器集成 # 除了执行命令格式化之外，更常用的是在编辑器中执行操作，比如保存文件时触发格式化。本文主要记录与Husky的联动，不打算深究这部分，具体参考 Editor Integration。\neslint-config-prettier # 注意⚠️：如果项目中同时使用了eslint和prettier，那么还需要 eslint-config-prettier，来避免eslint和prettier配置的冲突。它会关闭所有非必要或者会导致与prettier冲突的ESLint规则。\nPrettier vs. Linters # Linters have two categories of rules:\nFormatting rules: eg: max-len, no-mixed-spaces-and-tabs, keyword-spacing, comma-style…\nPrettier alleviates the need for this whole category of rules! Prettier is going to reprint the entire program from scratch in a consistent way, so it’s not possible for the programmer to make a mistake there anymore :)\nCode-quality rules: eg no-unused-vars, no-extra-bind, no-implicit-globals, prefer-promise-reject-errors…\nPrettier does nothing to help with those kind of rules. They are also the most important ones provided by linters as they are likely to catch real bugs with your code!\nIn other words, use Prettier for formatting and linters for catching bugs!\n总儿颜值就是，使用Prettier来格式化代码，linters来抑制bug。\nlinters的一个代表就是eslint：eslint是一个按照规则执行代码检查的工具，它可以在编码阶段进行静态分析，给出检查报告。搭配一些插件，可以提前暴露问题，给出提示，并进行修复，大大减少执行过程中的bug。\nlint-staged # lint-staged是一个在**git暂存文件(staged)**上运行linters的工具。 官方的原文是：\nRun linters against staged git files and don\u0026rsquo;t let 💩 slip into your code base!\n它的好处是：\nBut running a lint process on a whole project is slow, and linting results can be irrelevant. Ultimately you only want to lint files that will be committed.\n安装 lint-staged # npm install --save-dev lint-staged 使用需要搭配husky和Prettier等工具，直接看 最佳实践部分。\ncommitlint # 从上文就可以得知，lint是一类按照规则执行检查的工具，commitlint就是一个git commit校验约束工具。它要求我们的提交记录符合 conventional-commits规范。\n安装 # npm install --save-dev @commitlint/{config-conventional,cli} echo \u0026#34;module.exports = {extends: [\u0026#39;@commitlint/config-conventional\u0026#39;]}\u0026#34; \u0026gt; commitlint.config.js 然后在配置文件中配置详细的规则。\n规则 # 详细规则参考： 官方文档。\nangular的案例 # 不同的编程语言还贴心地给出了不同的提交规范，一般我只需要吧extends的类型修改一下即可。\nnpm install --save-dev @commitlint/config-angular @commitlint/cli echo \u0026#34;module.exports = {extends: [\u0026#39;@commitlint/config-angular\u0026#39;]};\u0026#34; \u0026gt; commitlint.config.js 与husky的结合 # 要在提交之前生效，需要添加如下钩子：\nnpx husky add .husky/commit-msg \u0026#39;npx --no -- commitlint --edit ${1}\u0026#39; 最佳实践 # 参考自： Prettier #Git hooks\n# prettier npm install --save-dev --save-exact prettier node --eval \u0026#34;fs.writeFileSync(\u0026#39;.prettierrc\u0026#39;,\u0026#39;{}\\n\u0026#39;)\u0026#34; # husky \u0026amp; lint-staged npm install --save-dev husky lint-staged npx husky install npm pkg set scripts.prepare=\u0026#34;husky install\u0026#34; npx husky add .husky/pre-commit \u0026#34;npx lint-staged\u0026#34; # commitlint npm install --save-dev @commitlint/{config-conventional,cli} echo \u0026#34;module.exports = {extends: [\u0026#39;@commitlint/config-conventional\u0026#39;]}\u0026#34; \u0026gt; commitlint.config.js npx husky add .husky/commit-msg \u0026#39;npx --no -- commitlint --edit ${1}\u0026#39; 然后在package.json中加入：\n{ \u0026#34;scripts\u0026#34;: { ... }, \u0026#34;lint-staged\u0026#34;: { \u0026#34;**/*\u0026#34;: \u0026#34;prettier --write --ignore-unknown\u0026#34; } } 这样就会在每次提交代码之前对所有支持的文件类型执行格式化操作。\n限制lint-staged的范围 # { \u0026#34;scripts\u0026#34;: { ... }, \u0026#34;lint-staged\u0026#34;: { \u0026#34;src/**/!(*.min).js\u0026#34;: [ \u0026#34;prettier --check\u0026#34;, ], \u0026#34;src/**/*.{ts,vue}\u0026#34;: [ \u0026#34;prettier --write\u0026#34;, ], \u0026#34;src/**/*.{ts,js,vue,html,css,scss,sass,stylus}\u0026#34;: [ \u0026#34;prettier --write\u0026#34; ] }, } 这样就会对不同的文件夹下面的不同文件类型的文件执行不同的脚本。\n","date":"5 November 2023","permalink":"/posts/2023/frontend/frontend-tool/","section":"","summary":"前言 # 如果你逛Github的话，就会发现很多项目根目录除了.","title":"Commit Better Code with Husky, Prettier, commitlint and Lint-Staged"},{"content":"","date":"5 November 2023","permalink":"/tags/%E4%BB%A3%E7%A0%81%E7%BE%8E%E5%8C%96/","section":"Tags","summary":"","title":"代码美化"},{"content":"","date":"19 October 2023","permalink":"/tags/github/","section":"Tags","summary":"","title":"Github"},{"content":"","date":"19 October 2023","permalink":"/tags/hugo/","section":"Tags","summary":"","title":"Hugo"},{"content":"仅仅是在Github Pages部署博客就有好几种方式，分别为：\n本地打包 Github Actions打包 以及\n部署到同一仓库 部署到不同仓库 这里我主要记录一下我用的本地打包并部署到同一仓库的方法。\n本地打包 + 部署到同一仓库 # 为什么要本地打包 # 说来话长，我使用的Hugo主题使用Github Actions打包总是会报错，但是本地打包又没有问题，网络上也没有搜到报错的解决方案。尝试几天解决无果后，遂退而求其次选择本地打包。\n打包和部署 # 首先在config.toml中把添加如下一行把build的分支从/public改到/docs。\npublishDir = \u0026#34;docs\u0026#34; 然后在项目根目录打开终端输入\nhugo 完成打包。打包完成后可以看到多了一个/docs文件夹（注意不要把这个文件夹加入.gitignore中）。接下来需要同时把打包后的结果push到远程分支（Github分支任意命名即可，不用遵守xxx.github.io的规则）。\n推送完成后进入Github对应分支的设置界面，点击Pages界面，把第三点设置为图上对应格式。如果有域名的话，在第四点那个填上对应域名。（域名这块我也是看的别人的博客，感兴趣的话网上很多教程）\n如果前面的设置都没有问题的话，接下来在Github的导航栏上点击Action，就能看到All workflows列表下有一个正在运行的workflows, 这是Github Actions自带的pages build and deployment workflow，也是为什么你把静态网页推动到Github仓库后就能访问到个人网站的原因。Github Actions提供了一个完整的CI/CD流程，如果对Github Actions想有更深入的了解的话，可以去参考官网文档。但对于只想搭建个人博客的同学来说，这已经足够应对了。\n访问 # 如果你之前没有填写自定义域名，那么你的博客地址是：\u0026lt;github user name\u0026gt;.github.io/\u0026lt;repository name\u0026gt;。比如如果你的Github用户名是abc,你这个仓库的名字是blog，那么你的访问地址就是：abc.github.io/blog。\n如果你之前填写了自定义域名，那么访问地址就是自定义域名。\nGithub Actions打包 + 部署到同一仓库 # Github Actions打包 # 这个方法主要区别是要写一个配置文件，但幸运的是，早已经有人写好了，我们直接复制别人写好的配置即可。配置在仓库目录 .github/workflows 下，以 .yml 为后缀即可，比如.github/workflows/blog-deploy.yml。\nname: deploy on: push: workflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: \u0026#34;0 0 * * *\u0026#34; jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; - name: Build Web run: hugo - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: pseudoyu/pseudoyu.github.io PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 上面的配置文件还设置了定时任务，如果不要可以删除这段：\nworkflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: \u0026#34;0 0 * * *\u0026#34; 如果想了解细节，参考：\nhttps://github.com/actions/checkout https://github.com/peaceiris/actions-hugo https://github.com/peaceiris/actions-gh-pages 部署 # 部署和上面的类似，只是分支从main变成了gh-pages分支，所以设置那里上图第三点需要把分支设置为gh-pages分支，目录设置为根目录。这样每次本地更新完内容后就直接推送到远程分支，等待Github Action完成打包和部署即可。\n","date":"19 October 2023","permalink":"/posts/2023/blog/blog_deploy/","section":"","summary":"仅仅是在Github Pages部署博客就有好几种方式，分别为：","title":"Hugo博客部署"},{"content":"","date":"19 October 2023","permalink":"/series/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E5%88%B0%E5%8F%91%E5%B8%83%E5%85%A8%E6%B5%81%E7%A8%8B/","section":"Series","summary":"","title":"博客搭建到发布全流程"},{"content":"","date":"19 October 2023","permalink":"/tags/%E9%83%A8%E7%BD%B2/","section":"Tags","summary":"","title":"部署"},{"content":"","date":"17 October 2023","permalink":"/","section":"你好，世界","summary":"","title":"你好，世界"},{"content":"前言 # 还记得第一次搭建博客是在大二，当时一个人带着电脑到教室学习算法，但是遇到苦难习惯性地开始不务正业，去折腾一些更简单的东西来寻求心理安慰。兜兜转转几年过去了，前前后后折腾了不少东西，但是技术也没有精进多少。现在想来，没有去挑战困难是大学最后悔的一件事。另外一件遗憾的事是很少记录生活，一些当初很感动的事情，现在也越来越模糊了。\n这也是我这次重新搭建博客的初衷，记录下自己的脚步，希望未来读档的时候不至于指针越界。\n静态博客主流方案 # 工具 Jekyll Hexo ｜ Hugo 介绍 Jekyll 是一个静态网站生成器，基于Ruby语言。 快速、简洁且高效的博客框架。 Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 优点 GitHub 支持好，历史最长，文档完备。 国人开发，入门简单。 基于Golang，生成速度快，社区活跃。 缺点 基于Ruby，在三种生成器中速度最慢。需要一定Ruby基础。 基于Node.js，生成速度一般。 入门简单，深入需要阅读英文文档。 曾经在V2EX看到过一个帖子说：\n一个是一群搞前端的人做的，一个是一群搞后端的人做的，特色都十分鲜明。\n深度体验下来，我觉得说的很有道理。\nHugo 安装 # Hugo官方文档地址： Quick start。安装照着教程来就可以了。\n如果使用Homebrew安装只需要：\nbrew install hugo 即可完成。\n安装完成后输入:\nhugo version 来确认是否安装完成。\n新建Hugo网站 # hugo new site site_name cd site_name git init 然后选择使用git submodule的方式来安装主题（还可以用go module的方式，不过我更喜欢git submodule）。\n设置主题 # 接下来去 Hugo主题网站挑选自己喜欢的主题。个人比较喜欢简洁现代风一点的：\nblowfish mini doIt 这里我选择的是 blowfish。\ngit submodule add -b main https://github.com/nunocoracao/blowfish.git themes/blowfish 接下来就是主题相关的配置了，你可以像我一样在终端的博客根目录输入code .进入VS Code进行配置。需要参考 blowfish官方文档(英文文档，需要适应一下)。\n根据文档内容，首先把现在根目录的config.toml文件删除，然后拷贝themes/blowfish/config/_default/目录下的所有toml后缀的文件到博客根目录下的config/_default/目录中。\n然后你就能启动项目看见主题的效果了：\nhugo server 通过 http://localhost:1313 访问。\n添加文章 # 首先先不考虑目录结构和文章分类等问题，跟着敲一遍下列命令新建第一篇文章：\nhugo new content posts/my-first-post.md Hugo会在content/posts目录下新建my-first-post.md文件，你可以随便写入些内容，符合markdown格式即可。比如:\n+++ title = \u0026#39;需要写点什么东西\u0026#39; date = 2023-10-14T11:56:21+08:00 draft = true +++ 不仅需要输入，更需要输出。做一个生产者。 然后在终端输入:\n# -D 意味着生成的内容包括草稿,如上所示，元数据里我加了一行draft = true，表明这个文件是一个草稿，如果不加-D参数的话不会被生成。 hugo server -D 命令重新生成并启动自带的服务器。通过 http://localhost:1313 访问查看效果。\n打包 # 命令很简单：\nhugo 打包的资源放在/public目录下。\n接下来 # 好了，这就是Hugo搭建博客的主要过程，但是如果要想写的得心应手，其实还需要阅读一下Hugo关于内容管理和模板等部分的文档。\n如果想要发布到网络上，还需要自己购买服务器，申请备案等等。不过GitHub Pages给我们提供了另一种选择，你可以不需要服务器，不需要购买域名，甚至不需要多少额外的配置就可以把博客发布到互联网上。\n欢迎阅读这个系列的下一章节。\n","date":"14 October 2023","permalink":"/posts/2023/blog/hugo_blog_build_up/","section":"","summary":"前言 # 还记得第一次搭建博客是在大二，当时一个人带着电脑到教室学习算法，但是遇到苦难习惯性地开始不务正业，去折腾一些更简单的东西来寻求心理安慰。兜兜转转几年过去了，前前后后折腾了不少东西，但是技术也没有精进多少。现在想来，没有去挑战困难是大学最后悔的一件事。另外一件遗憾的事是很少记录生活，一些当初很感动的事情，现在也越来越模糊了。","title":"Hugo博客搭建"},{"content":"羡慕那些能表达出文字的力量的人，寥寥数语，就能让我感受到内心的宁静，或者唤醒沉睡的另一个自己。\n","date":"14 October 2023","permalink":"/diary/2023/2023-10-14-first-diary/","section":"","summary":"羡慕那些能表达出文字的力量的人，寥寥数语，就能让我感受到内心的宁静，或者唤醒沉睡的另一个自己。","title":"需要写点什么东西的冲动"},{"content":" Hi there,\nMy name is Terry, 22 years old. Here is my personal blog site where I will record my daily life and programming experience.\nHopefully, we can all find something from here.\nBest wishes,\nTerry\n","date":"7 October 2023","permalink":"/about/","section":"你好，世界","summary":"Hi there,","title":"About"},{"content":"散落的笔记： https://a-fly-fly-bird.github.io/docsify-notes/#/\n","date":"1 January 0001","permalink":"/posts/docsify/","section":"","summary":"散落的笔记： https://a-fly-fly-bird.","title":""},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"}]